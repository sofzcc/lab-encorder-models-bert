{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-JnK7Zkhmj6"
      },
      "source": [
        "# Lab | Encorder Models - BERT\n",
        "\n",
        "---\n",
        "\n",
        "### Transformers' main components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2v9wkhQhuf4"
      },
      "source": [
        "**Hugging Face Transformers has two main components:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHkp89twf4Zq"
      },
      "source": [
        "\n",
        "1. The **tokenizer** prepares the text in a clean format, which the model understands.\n",
        "    - A token is a word or a sub-word unit. In BERT's vocabulary, the word \"good\" is one token and the word \"darwinism\" is two tokens  (\"darwin\" and \"ism\")\n",
        "    - The tokenizer transforms words into token-ids. With these token-ids, BERT can link words to any token it has already learned during pre-training.\n",
        "\n",
        "2. The **model** processes the tokenizer's ouput and returns a prediction, e.g. which class an input text belongs to.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4tmhG0piJ0P"
      },
      "source": [
        "Independently of the type of model (classification, summarisation, translation, etc.), these two components are almost the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TNjndqEeVP5h",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#!pip install transformers~=4.31.0  # The Transformers library from Hugging Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0axlrhOhTGu"
      },
      "source": [
        "## Models like BERT (encoders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "hykl2GkBhq5F",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HneEleBYh_tY"
      },
      "outputs": [],
      "source": [
        "# load any classification model from the HuggingFace model hub\n",
        "# See here: https://huggingface.co/models?pipeline_tag=text-classification\n",
        "\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "# instantiate the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# instantiate the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zluWT2EpHd64"
      },
      "source": [
        "### Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLKD6HULf4hX",
        "outputId": "d5616dbe-69cd-4ad8-b8f0-8825e148acee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: 'I believe that the EU is trustworthy.'\n",
            "\n",
            "The tokenizer splits the text string into separate tokens. A token is either an entire word,\n",
            "or a 'sub-word unit' in case of rare words (or punctuation).\n",
            "The word 'trustworthy', for example is split into two tokens: ['trust', '##worthy'].\n",
            "The main advantage of these sub-word units is that rare words cannot be out-of-vocabulary (an issue of other text-as-data approaches).\n",
            "Transformer models typically have a vocabulary of around 30.000 - 250.000 tokens, learned from the training data.\n",
            "Here is e.g. the vocabulary of DistilBERT: https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt\n",
            "\n",
            "The input text is split into the following tokens:\n",
            "['i', 'believe', 'that', 'the', 'eu', 'is', 'trust', '##worthy', '.'].\n",
            "The tokenizer then maps each token to the corresponding token ID in the model's vocabulary:\n",
            "[1045, 2903, 2008, 1996, 7327, 2003, 3404, 13966, 1012]\n",
            "Transformer models only understand these token IDs.\n",
            "\n",
            "In addition, the tokenizer adds two special tokens:\n",
            " First, the [CLS] (classification) token is always added at the beginning.\n",
            "        While individual tokens represent individual (sub)words, the [CLS] token represents the entire text.\n",
            "        The [CLS] token \"is  used  as  the  aggregate sequence representation for classification tasks\" (Devlin et al. 2019: 4). Details: https://arxiv.org/pdf/1810.04805.pdf\n",
            " Second, the [SEP] token separates two texts. It is useful for tasks which require two text inputs, for example Questions & Answer tasks.\n",
            "        (It is not relevant in our case)\n",
            "\n",
            "\n",
            "The final input for a BERT transformer model therefore looks like this:\n",
            "101  ==  [CLS]\n",
            "1045  ==  i\n",
            "2903  ==  believe\n",
            "2008  ==  that\n",
            "1996  ==  the\n",
            "7327  ==  eu\n",
            "2003  ==  is\n",
            "3404  ==  trust\n",
            "13966  ==  ##worthy\n",
            "1012  ==  .\n",
            "102  ==  [SEP]\n"
          ]
        }
      ],
      "source": [
        "### 1. Tokenization\n",
        "# Tokenizer documentation: https://huggingface.co/transformers/main_classes/tokenizer.html\n",
        "\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "print(f\"Input text: '{text}'\\n\")\n",
        "\n",
        "input_ids = tokenizer(text, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "print(f\"\"\"The tokenizer splits the text string into separate tokens. A token is either an entire word,\n",
        "or a 'sub-word unit' in case of rare words (or punctuation).\n",
        "The word 'trustworthy', for example is split into two tokens: {tokenizer.tokenize(\"Trustworthy\")}.\n",
        "The main advantage of these sub-word units is that rare words cannot be out-of-vocabulary (an issue of other text-as-data approaches).\n",
        "Transformer models typically have a vocabulary of around 30.000 - 250.000 tokens, learned from the training data.\n",
        "Here is e.g. the vocabulary of DistilBERT: https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt\\n\"\"\")\n",
        "\n",
        "print(f\"The input text is split into the following tokens:\\n{tokenizer.tokenize(text)}.\")\n",
        "print(\"The tokenizer then maps each token to the corresponding token ID in the model's vocabulary:\")\n",
        "print(input_ids[0].tolist()[1:-1])\n",
        "print(\"Transformer models only understand these token IDs.\\n\")\n",
        "\n",
        "print(\"\"\"In addition, the tokenizer adds two special tokens:\n",
        " First, the [CLS] (classification) token is always added at the beginning.\n",
        "        While individual tokens represent individual (sub)words, the [CLS] token represents the entire text.\n",
        "        The [CLS] token \"is  used  as  the  aggregate sequence representation for classification tasks\" (Devlin et al. 2019: 4). Details: https://arxiv.org/pdf/1810.04805.pdf\n",
        " Second, the [SEP] token separates two texts. It is useful for tasks which require two text inputs, for example Questions & Answer tasks.\n",
        "        (It is not relevant in our case)\n",
        "\\n\"\"\")\n",
        "\n",
        "print(\"\"\"The final input for a BERT transformer model therefore looks like this:\"\"\")\n",
        "token_strings = tokenizer.convert_ids_to_tokens(ids=input_ids[0])\n",
        "#token_strings = tokenizer.tokenize(text)\n",
        "for token_id, token_string in zip(input_ids[0].tolist(), token_strings):\n",
        "  print(token_id, \" == \", token_string)\n",
        "\n",
        "\n",
        "# entire vocabulary: tokenizer.pretrained_vocab_files_map[\"vocab_file\"][\"distilbert-base-uncased\"]\n",
        "# https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw7qQhjGcZ8d"
      },
      "source": [
        "### Tokens (words) flowing through the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z8vNYtliIaJ",
        "outputId": "a68cfacd-bb9b-48ea-ea19-3fa20de0dfef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After the preprocessing by the tokenizer, the model then feeds the sequence of tokens through the neural network.\n",
            "Each token is represented by a vector of 768 numbers (a 768 dimensional tensor).\n",
            "The tensor for the token \"trust\" looks for example like this before being fed into the first neural network layer\n",
            "(only 100 numbers are displayed):\n",
            "\n",
            "tensor([-0.0263, -0.0292, -0.0186,  0.0289,  0.0225,  0.0005, -0.0649,  0.0440,\n",
            "         0.0201,  0.0052, -0.0857, -0.0903, -0.0182, -0.0214, -0.0514, -0.0074,\n",
            "        -0.0361, -0.0715,  0.0125, -0.0320, -0.0118, -0.0252, -0.0431, -0.0383,\n",
            "         0.0073,  0.0188,  0.0049, -0.0829, -0.0150, -0.0313, -0.0517,  0.0518,\n",
            "         0.0099,  0.0418, -0.0135, -0.0256, -0.0432, -0.0029, -0.0191,  0.0006,\n",
            "         0.0023,  0.0052, -0.0705, -0.0053, -0.0237, -0.0131,  0.0082, -0.0160,\n",
            "        -0.0512,  0.0171,  0.0104, -0.0164, -0.0536, -0.0759, -0.0407, -0.0006,\n",
            "        -0.0331, -0.0792,  0.0354, -0.0010, -0.0222, -0.0015, -0.0628, -0.0206,\n",
            "        -0.1149, -0.0215, -0.0275, -0.0074, -0.0037,  0.0314, -0.0694, -0.0056,\n",
            "        -0.0402, -0.0959, -0.1495, -0.0860, -0.0756, -0.0939, -0.0162,  0.0127,\n",
            "        -0.0333, -0.0174, -0.0606, -0.0488,  0.0328, -0.0653, -0.0148,  0.0429,\n",
            "        -0.0382,  0.0021,  0.0154, -0.0832, -0.0312,  0.0751, -0.0100, -0.0326,\n",
            "         0.0089, -0.0080, -0.0745, -0.0516], grad_fn=<SliceBackward0>) \n",
            "\n",
            "The tensors for each token are then fed through and transformed by between 6-24~ neural network layers.\n",
            "\n",
            "Same word after the first layer:\n",
            "\n",
            " tensor([ 1.0197, -0.5487,  0.3499,  0.4607,  0.8391, -0.1893, -1.2744,  0.4050,\n",
            "         0.5758,  0.5190, -1.3808, -0.4710,  0.1655, -0.9737, -0.9132,  0.0945,\n",
            "         0.1522, -0.7325,  0.4531, -0.1877, -0.0658,  0.5347, -0.2890,  0.2111,\n",
            "         0.0095,  1.8999,  0.3661, -0.1923, -0.1967,  0.0840, -0.9437,  0.6535,\n",
            "         0.8659,  1.1503,  0.5523, -0.0571, -0.5224,  0.5320,  0.4575,  0.0705,\n",
            "         0.5444,  0.6075, -0.5054,  0.6493, -0.7816, -0.1386,  0.9620,  0.1940,\n",
            "         0.2520,  0.2409,  0.3830, -0.0106, -0.9761, -0.4375, -0.1450,  0.3104,\n",
            "        -0.4289, -0.2048,  0.7036,  0.0452,  0.3296,  0.4499,  0.4429, -0.7283,\n",
            "        -2.3567,  0.3876, -0.9062,  0.0851, -0.0852,  0.0829, -0.8152, -0.3009,\n",
            "        -0.6328, -1.0584, -2.2323, -0.9247, -1.3073, -0.2668,  0.3371,  0.0062,\n",
            "         0.2274, -0.0837, -1.3364, -0.1008,  0.2650, -1.4553,  0.6272,  0.5761,\n",
            "        -0.1431, -0.0612, -0.0905, -0.8610, -0.4050,  1.5188,  0.6204, -0.2890,\n",
            "         0.3655,  0.1397, -1.0399, -0.5957], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Same word after the second layer:\n",
            "\n",
            " tensor([ 8.6304e-01, -8.6820e-01,  7.8730e-01, -2.2138e-01,  1.2101e+00,\n",
            "         3.8670e-01, -1.0896e+00,  8.7422e-02,  4.7191e-01,  3.4434e-02,\n",
            "        -1.0020e+00,  6.2982e-01, -1.2089e-01, -5.2946e-01, -1.1913e+00,\n",
            "        -4.6408e-01,  1.9621e-02, -7.6431e-01, -4.3572e-01, -2.6467e-01,\n",
            "         1.8397e-01,  1.6879e-01,  3.4552e-02,  3.8005e-01, -1.0561e+00,\n",
            "         1.5122e+00,  8.2248e-01,  1.1769e-02,  6.4608e-02,  7.2765e-01,\n",
            "        -6.4231e-01, -1.5866e-02,  3.4216e-01,  1.7413e+00,  4.9454e-01,\n",
            "        -5.1311e-01, -3.9811e-01,  3.1635e-01,  9.2214e-01, -5.0008e-02,\n",
            "        -1.1514e-01,  6.3453e-01, -2.1229e-02,  5.0645e-01, -3.6516e-01,\n",
            "         9.9460e-02,  5.1015e-01, -2.4458e-01, -7.1837e-02, -1.2050e-01,\n",
            "        -1.2111e-01, -5.2317e-01, -9.3992e-01, -3.8500e-01,  1.9844e-01,\n",
            "        -7.1985e-01, -1.7236e+00, -2.9698e-01,  5.4476e-01,  6.2087e-01,\n",
            "         1.1353e+00,  4.7975e-02,  7.7644e-02, -1.1994e+00, -1.6474e+00,\n",
            "        -8.3196e-02, -7.1110e-01,  4.4613e-01, -1.4741e-01, -1.5835e-02,\n",
            "         9.5758e-04, -1.7963e-01, -2.0893e-01, -8.2586e-01, -1.6915e+00,\n",
            "        -3.0478e-01, -7.3935e-01, -3.4275e-01,  7.6856e-01, -1.3046e-01,\n",
            "         6.7788e-01, -1.4471e-01, -1.2505e+00, -2.1345e-01, -2.3939e-01,\n",
            "        -1.3216e+00,  1.0545e+00, -1.3779e-01, -2.7386e-01,  3.0029e-01,\n",
            "        -6.4045e-01, -9.0891e-01,  1.5595e-01,  1.4556e+00,  4.6438e-01,\n",
            "        -8.5181e-02,  5.4725e-01,  3.0987e-01, -6.2029e-01, -6.2813e-01],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Same word after the third layer:\n",
            " tensor([ 0.9212, -0.7324,  1.0849,  0.1285,  1.7201,  0.1206, -1.2363,  0.3248,\n",
            "         0.2296, -0.4176, -1.2181,  0.7761,  0.3709, -0.3074, -1.0410, -0.8390,\n",
            "         0.3025, -0.8386, -0.2958, -0.7338,  0.2495,  0.1852, -0.4483,  0.1946,\n",
            "        -0.9527,  1.4483,  1.2551, -0.1517, -0.1468,  0.5934, -0.3835, -0.4990,\n",
            "         0.1083,  2.1255,  0.2828, -0.4452, -0.6480,  0.3006,  0.8833, -0.1933,\n",
            "         0.8245,  0.0229,  0.5225,  0.5090, -0.1219, -0.0115,  0.4371,  0.1191,\n",
            "         0.4769, -0.5933, -0.5048, -0.1598, -1.1101, -0.3129, -0.0999, -0.4331,\n",
            "        -1.4321, -0.5000,  0.8986,  0.1585,  0.8666,  0.1234,  0.3061, -0.7799,\n",
            "        -2.0893, -0.0264, -0.0170,  0.4278, -0.1519, -0.1396, -0.4692, -0.6240,\n",
            "        -0.6900, -0.4560, -1.6708, -0.3217, -1.1698, -0.5013,  0.3791, -0.4421,\n",
            "         0.5225,  0.0037, -1.2145, -0.3596, -0.5739, -0.9433,  1.1805,  0.1375,\n",
            "        -0.0193,  0.0446,  0.0706, -0.4326,  0.2926,  1.2411,  0.3861, -0.3784,\n",
            "         0.7482,  0.7308, -0.0741, -0.7624], grad_fn=<SliceBackward0>) \n",
            "\n",
            "\n",
            " ... etc ...\n",
            "\n",
            "The final output is a a contextualised representation of the sequence: \"I believe that the EU is trustworthy.\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.8047,  0.0089,  0.3795, -0.0555,  0.7774, -0.5579, -0.1207,  0.1399,\n",
              "        -0.5552, -0.5563, -0.5408,  0.2092,  0.6960, -0.0485,  0.2146, -0.0739,\n",
              "         1.2168,  0.7535,  0.3837, -1.3671, -0.8294, -0.8162, -0.1873,  1.2271,\n",
              "        -0.0849,  0.1723, -0.2997,  0.2529, -0.0572, -0.2210,  0.4425, -0.3184,\n",
              "        -0.6751,  0.1786, -0.1515,  0.4018, -0.1430,  0.3645, -1.4429, -0.5780,\n",
              "         0.4491,  0.0273,  1.2017, -0.8200, -1.2773, -1.3720, -0.6155,  0.9188,\n",
              "         0.5872, -0.1749, -0.0137,  0.4098, -1.0665, -0.0121,  0.7994,  0.8794,\n",
              "        -0.4617,  0.3749, -0.3103, -1.6463, -0.5423, -0.3072,  0.3960, -0.2808,\n",
              "         1.0619,  0.3315,  0.3183,  0.2796, -0.0184,  0.4504, -0.0827, -0.2404,\n",
              "        -0.1939,  0.0236, -1.3192, -0.3731, -0.6895, -0.1810, -0.0960,  0.8422,\n",
              "        -0.2043,  0.0922,  0.0669,  0.9053, -0.6090,  0.3527,  0.7593,  0.2933,\n",
              "        -0.9349,  0.2980, -0.2813, -0.0948, -1.0958,  0.0020,  0.5932,  0.2225,\n",
              "        -0.0738, -0.1119, -0.7301, -0.3791], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "### Processing the input with the model\n",
        "# Model class documentation: https://huggingface.co/transformers/main_classes/model.html\n",
        "# Documentation for DistilBERT specifically: https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "\n",
        "print(f\"\"\"\\nAfter the preprocessing by the tokenizer, the model then feeds the sequence of tokens through the neural network.\n",
        "Each token is represented by a vector of 768 numbers (a 768 dimensional tensor).\n",
        "The tensor for the token \"trust\" looks for example like this before being fed into the first neural network layer\n",
        "(only 100 numbers are displayed):\\n\"\"\")\n",
        "print(model.distilbert.embeddings.word_embeddings(input_ids[0][7])[:100], \"\\n\")\n",
        "\n",
        "print(f\"\"\"The tensors for each token are then fed through and transformed by between 6-24~ neural network layers.\\n\"\"\")\n",
        "\n",
        "output = model(input_ids, output_hidden_states=True, output_attentions=False, return_dict=True)\n",
        "print(\"Same word after the first layer:\\n\\n\", output.hidden_states[1][0][7][:100], \"\\n\")  # same word embedding after the first attention layer\n",
        "print(\"Same word after the second layer:\\n\\n\", output.hidden_states[2][0][7][:100], \"\\n\")  # same word embedding after the second attention layer\n",
        "print(\"Same word after the third layer:\\n\", output.hidden_states[3][0][7][:100], \"\\n\")  # same word embedding after the third attention layer\n",
        "print(\"\\n ... etc ...\\n\")\n",
        "\n",
        "print(f'The final output is a a contextualised representation of the sequence: \"{text}\"')\n",
        "output.hidden_states[6][0][0][:100]  # final CLS token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ey7iZ13DsoKa",
        "outputId": "f4246363-cd5a-4fd0-9df5-39185cb8620e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is what the different model layers ('the architecture') look like:\n",
            "\n",
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(\"This is what the different model layers ('the architecture') look like:\\n\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNThz6Mdc6Ei"
      },
      "source": [
        "### The final output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ecRDjcsh-Z",
        "outputId": "75e836c8-366f-43eb-ce40-94e223b16b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At the end, Transformer models always output so called 'logits',\n",
            " one number for each class the model was trained to classify text into.\n",
            "\n",
            "Our input text was: 'I believe that the EU is trustworthy.'\n",
            "\n",
            "These logis represent the predicted probability for our binary sentiment classification task:\n",
            "\n",
            "[-3.5054750442504883, 3.680955648422241]\n",
            "\n",
            "Logits are not very interpretable, so they are then converted to percentages.\n",
            "Each percentages represents the model's prediction, which class the input text belongs to.\n",
            "\n",
            "{'NEGATIVE': 0.1, 'POSITIVE': 99.9}\n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"At the end, Transformer models always output so called 'logits',\\n one number for each class the model was trained to classify text into.\\n\n",
        "Our input text was: '{text}'\\n\n",
        "These logis represent the predicted probability for our binary sentiment classification task:\\n\\n{output[\"logits\"][0].tolist()}\\n\"\"\")\n",
        "\n",
        "print(\"Logits are not very interpretable, so they are then converted to percentages.\\nEach percentages represents the model's prediction, which class the input text belongs to.\\n\")\n",
        "probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "label_names = model.config.id2label.values()\n",
        "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(probabilities, label_names)}\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_AJJsLQHq3l"
      },
      "source": [
        "### Everything put together\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZK019KRAxHm",
        "outputId": "0a1d77d9-aff2-4465-f3ce-b6b63294ed1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'NEGATIVE': 0.1, 'POSITIVE': 99.9}\n"
          ]
        }
      ],
      "source": [
        "## In short, the code looks like this:\n",
        "\n",
        "# load the relevant functions from HuggingFace and PyTorch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "# Choose any classification model from the model hub\n",
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "\n",
        "# instantiate the tokenizer and the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# tokenization\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "input = tokenizer(text, truncation=True, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# model prediction\n",
        "output = model(input, output_hidden_states=False, output_attentions=False, return_dict=True)\n",
        "probabilities = torch.softmax(output[\"logits\"][0], -1).tolist()\n",
        "label_names = model.config.id2label.values()\n",
        "prediction = {name: round(float(pred) * 100, 1) for pred, name in zip(probabilities, label_names)}\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrJNiO8HBX8v",
        "outputId": "983f02bb-096b-4771-b20c-268977a7b37f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'label': 'POSITIVE', 'score': 0.9992438554763794},\n",
              "  {'label': 'NEGATIVE', 'score': 0.0007562130922451615}]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "## Or via the simplified pipeline:\n",
        "from transformers import pipeline\n",
        "pipe_classification = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\", top_k=2)\n",
        "text = 'I believe that the EU is trustworthy.'\n",
        "pipe_classification(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCq3Nf6-z4LS"
      },
      "source": [
        "## Generative models like GPT (decoders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R3RIWJj0DBf",
        "outputId": "87f07c38-8168-47c3-ae9c-002b8803a0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Today I can't believe we can finally get this done. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so sorry. I'm so\"]\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# https://huggingface.co/gpt2\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Today I can't believe we can finally\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**inputs, max_length=50)\n",
        "\n",
        "outputs_decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(outputs_decoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_FR2ctZ0yvG",
        "outputId": "e24dc5e8-2c25-4a2e-e0de-b2ef7e8ba503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The output looks quite messy:\n",
            "\n",
            "GenerateDecoderOnlyOutput(sequences=tensor([[8888,  314, 1975,  356,  460, 3443,  651,  284,  262,  966,  810,  356,\n",
            "          460,  787,  257, 3580,  287,  262, 3160,  286,  262,  661,  286,  262,\n",
            "         1578, 1829,  286, 2253,   13,  198]]), scores=(tensor([[-148.6821, -149.2908, -156.0585,  ..., -162.4585, -158.8699,\n",
            "         -150.9391]]), tensor([[-115.6685, -116.1133, -120.9430,  ..., -121.5678, -122.0460,\n",
            "         -116.7151]]), tensor([[-102.9193, -102.8433, -106.7674,  ..., -109.7448, -110.1562,\n",
            "         -104.3626]]), tensor([[-113.0016, -111.4651, -116.1575,  ..., -115.7575, -119.9194,\n",
            "         -112.3750]]), tensor([[-85.0493, -86.2461, -92.9495,  ..., -96.9331, -97.5099, -88.6309]]), tensor([[-101.4949, -101.3607, -106.5000,  ..., -105.3604, -108.2616,\n",
            "         -102.6193]]), tensor([[-144.4079, -143.1993, -147.8557,  ..., -153.8577, -149.4084,\n",
            "         -145.1063]]), tensor([[-142.9678, -142.7155, -149.5450,  ..., -154.4601, -153.3980,\n",
            "         -144.9618]]), tensor([[-107.0143, -106.5294, -112.6670,  ..., -110.6300, -114.1609,\n",
            "         -108.2180]]), tensor([[-136.4495, -134.5512, -138.7625,  ..., -143.6068, -142.1176,\n",
            "         -135.7249]]), tensor([[-109.8607, -109.8173, -119.3194,  ..., -124.9032, -125.0525,\n",
            "         -113.8864]]), tensor([[-106.7517, -105.5091, -110.3003,  ..., -111.1602, -112.8438,\n",
            "         -107.1499]]), tensor([[-130.9350, -128.7390, -133.6040,  ..., -132.8403, -135.4675,\n",
            "         -129.3462]]), tensor([[-39.1257, -36.0714, -45.9913,  ..., -49.6895, -46.9359, -41.5145]]), tensor([[-123.4334, -122.4138, -127.8127,  ..., -124.1029, -129.7924,\n",
            "         -123.4686]]), tensor([[-125.3868, -123.8290, -128.6104,  ..., -124.4080, -129.1839,\n",
            "         -124.1066]]), tensor([[-110.4702, -109.6479, -119.3325,  ..., -122.6706, -120.5586,\n",
            "         -114.1836]]), tensor([[ -97.1338,  -96.7021, -100.0708,  ..., -101.8569, -104.7260,\n",
            "          -97.4859]]), tensor([[-116.5378, -115.0052, -118.4467,  ..., -117.5226, -121.5478,\n",
            "         -115.1521]]), tensor([[-223.0999, -221.9221, -225.2948,  ..., -236.5789, -240.2266,\n",
            "         -223.4586]]), tensor([[-82.4273, -81.1039, -90.4331,  ..., -95.9789, -96.0215, -85.2337]]), tensor([[-178.7831, -180.3468, -182.6520,  ..., -186.7446, -193.9576,\n",
            "         -179.8749]]), tensor([[ -92.5517,  -92.2312, -100.1863,  ..., -108.7172, -106.8259,\n",
            "          -95.7613]]), tensor([[-160.1644, -159.1199, -159.8176,  ..., -175.6871, -177.5045,\n",
            "         -151.5896]])), logits=None, attentions=None, hidden_states=None, past_key_values=((tensor([[[[-7.0634e-01,  1.9011e+00,  7.7253e-01,  ..., -1.3028e+00,\n",
            "           -5.0432e-01,  1.6823e+00],\n",
            "          [-2.4647e+00,  2.4373e+00,  2.5695e+00,  ..., -1.3429e+00,\n",
            "           -1.6592e+00,  1.9584e+00],\n",
            "          [-1.9873e+00,  1.6619e+00,  2.0917e+00,  ..., -1.9292e+00,\n",
            "           -1.2148e+00,  1.1978e+00],\n",
            "          ...,\n",
            "          [-2.7127e+00,  2.4865e+00,  1.9309e+00,  ..., -1.1141e+00,\n",
            "           -2.2829e+00,  2.6243e+00],\n",
            "          [-2.7075e+00,  2.8348e+00,  1.0344e+00,  ...,  3.8028e-01,\n",
            "           -1.9100e+00,  1.0236e+00],\n",
            "          [-2.5097e+00,  2.2639e+00,  2.3698e+00,  ..., -2.3063e-01,\n",
            "           -2.1063e+00,  1.4775e+00]],\n",
            "\n",
            "         [[-9.6153e-02,  8.9928e-01, -1.4324e+00,  ..., -3.8667e-03,\n",
            "            1.7698e+00,  6.0074e-01],\n",
            "          [-8.8567e-01, -2.3526e+00, -3.3929e+00,  ..., -1.1976e+00,\n",
            "            3.3305e+00, -3.1990e-01],\n",
            "          [ 7.9695e-01, -8.0059e-01, -9.0706e-01,  ...,  2.5168e-01,\n",
            "            4.2648e+00,  2.0789e+00],\n",
            "          ...,\n",
            "          [ 6.1307e-01, -9.5665e-01, -1.5936e+00,  ..., -1.4241e+00,\n",
            "            2.6073e+00, -2.4871e+00],\n",
            "          [ 4.2210e-01, -4.8425e-01, -3.1538e+00,  ..., -2.3537e+00,\n",
            "            3.3508e+00, -8.7462e-02],\n",
            "          [-9.5869e-01, -4.1154e-01, -1.7378e+00,  ..., -2.8279e-01,\n",
            "            6.2255e-01,  2.2902e-01]],\n",
            "\n",
            "         [[-1.4670e-01,  2.1407e-01,  1.1498e+00,  ..., -1.3128e+00,\n",
            "           -2.1007e+00,  5.6910e-01],\n",
            "          [ 7.7998e-01,  3.1798e-01,  3.9369e-01,  ..., -2.2894e+00,\n",
            "            4.3988e-01,  1.7516e+00],\n",
            "          [ 6.2313e-01,  6.7045e-01,  4.9209e-01,  ..., -2.6860e+00,\n",
            "            1.5650e-01,  2.0049e+00],\n",
            "          ...,\n",
            "          [ 6.3691e-01,  2.4749e-02,  4.0601e-01,  ..., -2.8468e+00,\n",
            "            1.5414e+00,  1.8368e+00],\n",
            "          [ 4.2248e-01, -1.3133e-02,  2.2438e+00,  ..., -3.4738e+00,\n",
            "            7.5057e-01, -8.3787e-02],\n",
            "          [-2.0842e-01, -2.1345e-02,  5.1994e-01,  ..., -2.3185e+00,\n",
            "            1.7095e+00,  1.9351e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4733e-01,  4.7672e-01, -2.2749e-01,  ...,  2.9014e-01,\n",
            "            7.7821e-01,  7.8295e-01],\n",
            "          [ 4.1218e-01,  3.5364e-02, -5.0671e-02,  ...,  7.3103e-01,\n",
            "            3.8803e-01,  1.9230e-01],\n",
            "          [ 2.8231e-01,  2.8083e-01,  2.9148e-02,  ...,  1.6237e+00,\n",
            "            4.9737e-01,  4.8033e-01],\n",
            "          ...,\n",
            "          [ 1.2813e-02, -1.0431e-01,  1.4588e-01,  ...,  1.3087e+00,\n",
            "            3.8228e-01,  5.8956e-01],\n",
            "          [ 8.3487e-01,  3.7840e-01,  2.4985e-01,  ...,  2.1633e+00,\n",
            "            8.6496e-01,  6.9218e-01],\n",
            "          [-1.6190e-01, -6.7540e-02,  9.7274e-02,  ...,  1.1339e+00,\n",
            "            1.9076e-01,  4.0327e-01]],\n",
            "\n",
            "         [[ 1.4700e+00,  1.3564e+00, -4.9892e-01,  ..., -6.4924e-02,\n",
            "            1.4507e+00, -1.2267e+00],\n",
            "          [ 9.6538e-01,  7.4425e-01, -5.9779e-01,  ..., -1.6136e+00,\n",
            "            1.7429e+00, -5.7866e-01],\n",
            "          [ 1.2687e+00,  6.1252e-01, -2.9011e-01,  ..., -1.1579e+00,\n",
            "            1.0860e+00, -3.8481e-02],\n",
            "          ...,\n",
            "          [ 9.5404e-01, -1.2810e+00, -4.7940e-01,  ..., -5.7983e-01,\n",
            "           -1.5645e-01,  5.7167e-01],\n",
            "          [ 2.0269e+00, -4.8958e-01, -6.0520e-01,  ..., -5.3377e-01,\n",
            "            1.2393e-01,  1.4422e-01],\n",
            "          [ 1.0130e+00, -4.9447e-01, -3.0291e-01,  ..., -5.3328e-01,\n",
            "           -2.8455e-01,  3.7270e-01]],\n",
            "\n",
            "         [[ 7.1643e-01, -3.1278e-01,  1.4058e-01,  ..., -2.0734e-01,\n",
            "            2.5946e-01,  1.7684e+00],\n",
            "          [-1.1371e-01,  8.2240e-01, -5.4853e-01,  ...,  1.0394e+00,\n",
            "            2.6792e-01,  1.5042e+00],\n",
            "          [ 5.3924e-01, -2.1505e-01, -4.6411e-02,  ..., -1.3775e-01,\n",
            "            2.6632e-01,  1.4949e+00],\n",
            "          ...,\n",
            "          [-4.1815e-01,  1.1403e+00, -1.1332e+00,  ...,  1.4879e+00,\n",
            "            1.4104e+00, -1.3878e+00],\n",
            "          [ 4.2660e-01,  1.2501e+00, -4.8304e-01,  ..., -1.1900e+00,\n",
            "            1.0336e+00,  4.0373e-01],\n",
            "          [-8.1175e-01,  8.3372e-01,  1.0109e+00,  ..., -5.8927e-01,\n",
            "            9.8211e-01, -1.4637e+00]]]]), tensor([[[[ 1.9004e-01,  1.5334e-03, -5.1680e-02,  ...,  5.3629e-02,\n",
            "            3.1161e-02, -6.9398e-02],\n",
            "          [ 3.9855e-03,  1.8084e-01,  5.0278e-02,  ...,  3.4498e-02,\n",
            "           -2.0896e-04, -4.3176e-02],\n",
            "          [ 2.6622e-01, -1.0463e-02,  1.6902e-01,  ...,  1.1578e-01,\n",
            "            1.4779e-01,  1.5304e-01],\n",
            "          ...,\n",
            "          [-1.5560e-02, -1.1297e-01, -7.8034e-02,  ..., -5.3549e-02,\n",
            "           -5.0648e-02,  2.0633e-01],\n",
            "          [ 1.8711e-01,  1.9235e-01,  8.1979e-02,  ..., -5.4704e-03,\n",
            "            2.2676e-03,  2.0692e-01],\n",
            "          [-2.7024e-01,  7.4793e-02, -3.3710e-01,  ..., -3.8791e-02,\n",
            "            9.4199e-02, -1.6016e-01]],\n",
            "\n",
            "         [[ 4.4063e-01,  1.1764e-01, -2.1364e-01,  ..., -6.8386e-01,\n",
            "           -2.3711e-01,  2.9988e-01],\n",
            "          [ 5.7491e-01, -3.7942e-01,  7.3961e-02,  ...,  4.3965e-02,\n",
            "            1.1994e-01, -1.0070e-01],\n",
            "          [ 5.1505e-01,  9.7597e-03, -5.3891e-02,  ...,  5.4740e-02,\n",
            "            1.5750e-01, -1.0660e-01],\n",
            "          ...,\n",
            "          [ 1.0131e-01, -7.5195e-02, -4.6248e-01,  ...,  2.5521e-02,\n",
            "            4.6034e-01,  1.8158e-01],\n",
            "          [-1.1155e-01, -2.5374e-01, -2.9783e-02,  ..., -3.5996e-01,\n",
            "           -1.1122e-01,  1.5999e-01],\n",
            "          [-3.4615e-02, -5.2452e-02,  2.7320e-02,  ...,  9.5073e-02,\n",
            "            5.2588e-01, -1.0236e-01]],\n",
            "\n",
            "         [[ 8.0986e-02, -1.9105e-01,  1.0920e-01,  ..., -2.8258e-02,\n",
            "            4.0846e-02,  9.6056e-02],\n",
            "          [-3.7596e-01,  1.4441e-02,  2.1320e-02,  ..., -1.2924e-01,\n",
            "           -1.0396e-01, -1.2596e-01],\n",
            "          [ 3.1988e-01, -8.0700e-02,  2.1108e-01,  ..., -4.5115e-02,\n",
            "            1.4615e-01, -9.1999e-02],\n",
            "          ...,\n",
            "          [ 3.4296e-01,  3.7000e-01,  6.0198e-01,  ..., -2.9883e-02,\n",
            "            1.0734e-01, -2.5554e-01],\n",
            "          [ 2.6652e-01, -1.2352e-01, -1.1305e-01,  ..., -2.1529e-01,\n",
            "           -2.5960e-02,  1.0062e-01],\n",
            "          [-3.2510e-01, -9.5211e-02,  9.8852e-02,  ..., -3.3780e-04,\n",
            "           -1.1354e-01, -9.3465e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1093e-02, -1.6837e-02,  2.6340e-02,  ..., -2.1347e-01,\n",
            "            2.0540e-01,  7.2873e-02],\n",
            "          [-3.3497e-01,  3.5590e-01,  2.9674e-01,  ..., -3.1429e-01,\n",
            "           -1.5763e-01, -1.8047e-01],\n",
            "          [ 1.6841e-01,  3.0142e-01, -1.5456e-01,  ...,  4.0152e-02,\n",
            "            3.1728e-02, -1.4461e-01],\n",
            "          ...,\n",
            "          [-1.6887e-01, -2.6492e-01, -5.1402e-02,  ..., -4.0372e-01,\n",
            "           -1.4591e-02, -2.8135e-01],\n",
            "          [-6.7072e-02,  3.2227e-01,  9.4185e-02,  ...,  4.3489e-01,\n",
            "           -1.8566e-02, -1.4726e-01],\n",
            "          [-1.4107e-01, -7.9414e-01,  5.1069e-03,  ...,  1.4829e-01,\n",
            "           -1.6708e-01, -2.4772e-02]],\n",
            "\n",
            "         [[ 2.0808e-01, -2.3991e-01, -1.3177e-01,  ...,  1.4707e-01,\n",
            "            1.1230e-01, -3.1638e-02],\n",
            "          [-1.0211e-01, -3.4330e-01, -1.4682e-01,  ..., -2.4212e-01,\n",
            "           -1.6067e-01,  4.3960e-01],\n",
            "          [-1.4885e-02, -1.5116e-01,  8.0318e-02,  ..., -3.0759e-01,\n",
            "           -3.3533e-02,  2.2352e-01],\n",
            "          ...,\n",
            "          [ 1.4046e-01,  1.4004e-01, -2.6898e-02,  ..., -7.1938e-02,\n",
            "           -1.7706e-01,  4.3694e-02],\n",
            "          [-4.5891e-02, -6.3777e-02, -2.3865e-01,  ..., -2.6554e-02,\n",
            "            1.3140e-01, -5.2559e-02],\n",
            "          [-7.9865e-04, -2.7231e-02, -2.4400e-02,  ...,  2.1503e-01,\n",
            "            2.7098e-01,  1.0744e-01]],\n",
            "\n",
            "         [[-6.8917e-02, -3.9548e-01,  2.3281e-01,  ...,  1.5386e-01,\n",
            "           -1.8228e-01, -8.4490e-02],\n",
            "          [-2.0912e-02, -6.2773e-02, -4.5736e-02,  ...,  1.0176e-01,\n",
            "            1.5009e-01,  3.1374e-01],\n",
            "          [-1.1194e-01,  1.1757e-01, -8.0822e-02,  ..., -4.3040e-02,\n",
            "            1.7277e-01,  5.2849e-02],\n",
            "          ...,\n",
            "          [ 1.4115e-01, -8.5589e-02,  2.9591e-01,  ...,  7.0563e-02,\n",
            "            2.3414e-01,  1.3799e-01],\n",
            "          [ 1.5683e-01,  2.2114e-01, -2.6050e-02,  ...,  1.2313e-01,\n",
            "            1.7339e-02, -2.2186e-01],\n",
            "          [ 1.0172e-01, -7.8293e-02, -4.1893e-02,  ...,  5.1589e-02,\n",
            "            5.5644e-02, -5.6281e-02]]]])), (tensor([[[[-3.5429e-01,  2.2092e+00, -1.5580e+00,  ...,  1.4397e+00,\n",
            "           -1.1504e+00,  1.4646e+00],\n",
            "          [ 1.1729e+00,  2.4437e+00, -1.3057e+00,  ..., -9.6245e-01,\n",
            "           -1.6459e+00, -1.3797e+00],\n",
            "          [ 8.3218e-01,  2.5289e+00, -1.9983e+00,  ..., -1.1703e+00,\n",
            "           -1.8826e+00, -2.7559e-01],\n",
            "          ...,\n",
            "          [-2.7376e+00,  8.5306e-01,  1.6765e+00,  ...,  1.6069e+00,\n",
            "           -1.1410e+00, -9.6258e-01],\n",
            "          [-3.1060e+00,  1.6226e+00,  1.4819e+00,  ...,  1.6859e+00,\n",
            "           -1.3178e+00, -4.2203e-01],\n",
            "          [-2.8385e+00,  4.0942e-01,  1.8931e+00,  ...,  1.6229e+00,\n",
            "            2.1832e-01, -8.7006e-01]],\n",
            "\n",
            "         [[-1.0087e+00, -4.5958e-01, -7.4797e-01,  ..., -3.7310e-01,\n",
            "            7.9809e-01, -2.3881e-01],\n",
            "          [-5.4285e-02,  9.8554e-03, -1.2734e+00,  ..., -3.5395e-02,\n",
            "            3.4861e-01, -8.7453e-02],\n",
            "          [-8.1333e-01,  4.9666e-01, -9.4061e-01,  ..., -9.2341e-01,\n",
            "            3.3077e-01, -5.4269e-01],\n",
            "          ...,\n",
            "          [ 4.1397e-01,  2.3312e+00, -3.0413e+00,  ...,  2.3673e-01,\n",
            "           -1.8436e+00, -6.6755e-01],\n",
            "          [ 5.7715e-01,  2.1431e+00, -3.7120e+00,  ...,  1.0805e+00,\n",
            "           -2.4201e+00, -7.0198e-01],\n",
            "          [-2.7357e-01,  2.3542e+00, -2.4199e+00,  ...,  3.7849e-01,\n",
            "           -1.7739e+00, -2.2419e-01]],\n",
            "\n",
            "         [[ 3.2591e-01, -1.6143e-02, -2.0098e-01,  ..., -1.3362e+00,\n",
            "            3.3876e-01, -1.6542e-01],\n",
            "          [ 6.7432e-02,  3.5637e-01, -7.2911e-02,  ..., -7.9753e-01,\n",
            "           -9.8086e-02,  4.0581e-01],\n",
            "          [ 1.9314e-01,  6.9869e-02, -2.8760e-01,  ..., -1.2517e+00,\n",
            "            3.3108e-02,  4.9400e-01],\n",
            "          ...,\n",
            "          [-1.5807e-01, -1.1009e-01,  1.8686e-01,  ..., -8.0338e-02,\n",
            "            4.8903e-02,  1.6072e-01],\n",
            "          [-6.6755e-01, -2.0059e-01, -2.5906e-01,  ...,  1.6152e-01,\n",
            "            1.1972e-01,  5.7571e-01],\n",
            "          [-2.6462e-01, -1.0867e-01, -1.7203e-02,  ..., -7.1189e-01,\n",
            "            1.5246e-04,  8.6836e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1528e-01, -4.6627e-01, -5.9642e-01,  ..., -4.2178e-01,\n",
            "            4.3739e-01, -8.5899e-01],\n",
            "          [ 5.3403e-01,  1.2730e+00,  1.7570e+00,  ...,  2.5821e+00,\n",
            "            4.1829e-01,  1.1409e-02],\n",
            "          [-2.2680e+00,  1.6609e+00,  1.9737e+00,  ..., -4.2990e-01,\n",
            "           -4.5606e-01,  1.6604e+00],\n",
            "          ...,\n",
            "          [ 1.1474e+00, -1.7796e+00,  1.6350e+00,  ...,  6.0652e-01,\n",
            "            4.6123e-01, -8.9973e-01],\n",
            "          [ 1.5471e+00, -2.4914e+00,  6.6991e-01,  ...,  1.1296e+00,\n",
            "            1.8906e+00, -1.7293e-01],\n",
            "          [-7.1093e-01, -5.8520e-02,  9.6706e-01,  ...,  4.1904e-03,\n",
            "           -1.6468e+00,  5.5909e-01]],\n",
            "\n",
            "         [[-1.1473e+00, -2.7966e+00,  1.4438e-01,  ...,  1.7208e+00,\n",
            "            1.5965e+00, -1.4860e+00],\n",
            "          [ 1.5517e-01,  9.9389e-01, -4.5958e-01,  ..., -7.2512e-01,\n",
            "            6.5299e-01, -5.5809e-02],\n",
            "          [-2.0161e-02,  4.7695e-01, -4.8925e-01,  ..., -3.4500e-01,\n",
            "            5.7439e-01,  2.3346e-01],\n",
            "          ...,\n",
            "          [-7.4427e-01,  1.9456e-01, -8.1970e-01,  ..., -6.3760e-01,\n",
            "            1.9411e+00,  4.7984e-01],\n",
            "          [-1.1504e+00,  2.7456e-01, -9.1319e-01,  ..., -1.7167e-01,\n",
            "            1.9417e+00,  1.0730e-01],\n",
            "          [-8.2611e-01,  7.9728e-02, -6.6100e-01,  ..., -4.2234e-02,\n",
            "            1.6927e+00, -6.2267e-02]],\n",
            "\n",
            "         [[ 1.3976e+00,  1.6241e+00,  5.4245e-01,  ..., -7.8420e-01,\n",
            "            1.1678e-01,  3.7706e-01],\n",
            "          [ 9.2373e-01,  2.7455e+00,  2.3158e+00,  ...,  1.2600e+00,\n",
            "           -8.7374e-01, -1.5959e+00],\n",
            "          [ 5.7432e-01,  1.7291e+00,  4.0909e-01,  ...,  1.9053e+00,\n",
            "           -7.8598e-03, -4.7148e-01],\n",
            "          ...,\n",
            "          [ 1.4249e+00,  1.8867e+00,  3.1110e-01,  ..., -3.0709e-01,\n",
            "           -7.9745e-01, -9.3498e-01],\n",
            "          [ 4.7398e-01,  1.2592e+00, -1.1109e+00,  ...,  2.4742e+00,\n",
            "            6.4329e-02, -1.5355e+00],\n",
            "          [ 6.5339e-01,  1.2125e+00,  7.9136e-01,  ..., -1.1916e+00,\n",
            "           -3.3998e-01,  1.3224e-01]]]]), tensor([[[[ 3.3872e-01,  1.3968e-01, -1.7938e-01,  ...,  1.5467e-01,\n",
            "           -1.2589e-01,  7.0887e-02],\n",
            "          [ 5.1316e-01,  2.6463e-01,  1.4795e-01,  ..., -5.0321e-01,\n",
            "            2.5885e-03, -5.4370e-02],\n",
            "          [ 8.7060e-01, -2.1953e-01,  1.2817e-01,  ..., -5.1551e-01,\n",
            "            5.3434e-02,  2.3025e-01],\n",
            "          ...,\n",
            "          [ 1.3724e-01,  4.0424e-01,  3.6770e-01,  ..., -3.1146e-01,\n",
            "           -2.4386e-01,  3.4858e-01],\n",
            "          [ 3.7101e-01,  5.5353e-01, -3.6406e-01,  ..., -2.5888e-01,\n",
            "           -2.6153e-01,  3.1346e-01],\n",
            "          [ 4.1563e-01,  1.0214e-01,  2.4296e-01,  ..., -6.9200e-02,\n",
            "           -3.0936e-01, -1.6652e-01]],\n",
            "\n",
            "         [[-7.9321e-02, -6.6966e-02, -2.2227e-01,  ..., -1.4152e-02,\n",
            "           -4.5964e-01,  2.7340e-01],\n",
            "          [-1.7110e-01,  2.2289e-01,  4.5916e-01,  ...,  4.0344e-01,\n",
            "           -5.7027e-01, -8.1914e-01],\n",
            "          [-1.8253e-01, -1.1166e+00,  2.0879e-01,  ..., -2.1142e-01,\n",
            "            5.5583e-01,  4.1799e-01],\n",
            "          ...,\n",
            "          [ 7.6490e-01,  3.6079e-01,  1.9160e-01,  ..., -1.0731e+00,\n",
            "            1.2514e-01,  1.4587e-01],\n",
            "          [-5.7648e-01,  5.9108e-01, -3.8838e-01,  ...,  6.1908e-01,\n",
            "            1.3537e-01,  8.1487e-02],\n",
            "          [ 9.2349e-02,  5.2726e-02,  5.1965e-02,  ...,  1.0475e-01,\n",
            "            3.0348e-01,  2.0018e-01]],\n",
            "\n",
            "         [[ 7.9376e-02, -1.4863e-02, -4.4028e-02,  ..., -6.2825e-01,\n",
            "            6.7841e-02,  1.0440e-02],\n",
            "          [ 6.5953e-01, -8.7403e-02,  4.6977e-01,  ..., -4.9772e-01,\n",
            "            2.5046e-01,  5.0100e-02],\n",
            "          [ 6.1330e-01,  8.1756e-02,  1.1879e-01,  ..., -7.5461e-01,\n",
            "           -3.7898e-01,  3.7405e-01],\n",
            "          ...,\n",
            "          [-1.4517e-01,  3.3737e-01, -5.5544e-02,  ...,  1.5846e+00,\n",
            "            3.6316e-01, -2.1912e-01],\n",
            "          [-3.1375e-01,  6.9019e-02,  9.0017e-02,  ...,  1.2659e+00,\n",
            "            1.8727e-01,  3.2046e-01],\n",
            "          [-4.7323e-01,  2.3832e-01,  3.3219e-01,  ...,  1.5924e+00,\n",
            "           -1.2583e-01, -3.6266e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0567e-01,  6.7946e-01, -1.7619e-01,  ...,  1.2480e-02,\n",
            "           -9.7338e-01, -2.5708e-01],\n",
            "          [-7.7235e-01, -8.7091e-02,  1.2979e-01,  ...,  2.5245e-01,\n",
            "           -8.8666e-01, -4.5180e-01],\n",
            "          [-8.1327e-01, -4.7569e-01, -8.0761e-01,  ..., -4.9155e-01,\n",
            "           -9.6759e-01, -2.3510e-01],\n",
            "          ...,\n",
            "          [ 1.2999e-01, -3.9156e-01, -1.3884e-01,  ...,  1.4332e-01,\n",
            "           -3.6852e-02, -1.9165e-01],\n",
            "          [-3.7671e-01,  6.8679e-01, -6.7554e-01,  ..., -8.2312e-02,\n",
            "            1.3162e-01, -4.5973e-01],\n",
            "          [ 5.8545e-02, -9.0701e-01,  1.1667e-01,  ...,  2.5942e-01,\n",
            "           -3.8478e-01, -3.1619e-01]],\n",
            "\n",
            "         [[ 4.7333e-02, -1.1130e-02, -1.4608e-01,  ...,  3.8364e-01,\n",
            "           -3.4244e+00,  6.6758e-02],\n",
            "          [ 3.6334e-01,  9.2942e-02,  3.0799e-01,  ...,  5.2007e-01,\n",
            "           -1.4175e-02, -5.1095e-02],\n",
            "          [-4.4324e-01, -1.9859e-01, -2.1946e-01,  ..., -9.0844e-02,\n",
            "            1.1947e-01,  1.7279e-01],\n",
            "          ...,\n",
            "          [ 2.2291e-01,  6.3616e-01, -2.5914e-01,  ..., -7.6591e-02,\n",
            "           -1.1669e-01, -1.3297e-01],\n",
            "          [ 2.6379e-01,  2.8475e-01, -2.3551e-01,  ...,  4.1289e-02,\n",
            "           -1.2160e-01,  4.3988e-02],\n",
            "          [ 6.3095e-01,  5.0644e-01, -1.0413e-01,  ...,  1.1321e-01,\n",
            "           -2.6217e-01, -2.0415e-02]],\n",
            "\n",
            "         [[ 2.4439e-02, -2.3092e-01,  1.1163e-02,  ..., -3.4285e-01,\n",
            "            2.7007e-01, -3.4211e-02],\n",
            "          [ 1.1372e-01, -4.8722e-01,  2.2197e-01,  ..., -3.3722e-02,\n",
            "            3.2452e-01,  2.7431e-01],\n",
            "          [ 9.0289e-02, -7.0778e-02,  6.2565e-02,  ...,  2.5245e-01,\n",
            "            2.6043e-01,  4.0083e-01],\n",
            "          ...,\n",
            "          [-2.1551e-01,  2.1521e-01,  5.1304e-02,  ...,  2.1200e-02,\n",
            "           -6.1686e-02,  1.4614e-01],\n",
            "          [-7.3142e-03, -9.8872e-02,  1.3906e-01,  ...,  4.5406e-01,\n",
            "            3.1668e-01,  1.5857e-01],\n",
            "          [ 3.1220e-01,  2.6670e-02,  5.4745e-01,  ...,  2.1037e-01,\n",
            "            3.3819e-01,  2.7370e-01]]]])), (tensor([[[[-1.5217e-01, -1.1477e+00,  2.3295e-01,  ..., -6.4279e-01,\n",
            "           -1.1349e-01,  4.0799e-02],\n",
            "          [ 3.2049e-01, -2.1934e+00, -6.7814e-02,  ..., -9.3208e-02,\n",
            "           -2.3660e-01, -5.0723e-01],\n",
            "          [-3.9667e-01, -2.5138e+00, -4.9042e-01,  ..., -9.8576e-01,\n",
            "            2.6136e-01, -1.9714e+00],\n",
            "          ...,\n",
            "          [-1.8886e-01,  5.4693e-01,  6.1053e-01,  ...,  2.2614e+00,\n",
            "            6.1887e-01,  3.9096e-02],\n",
            "          [ 3.1898e-01, -7.4856e-01,  1.0752e-01,  ...,  1.1979e+00,\n",
            "            1.5261e+00,  7.2886e-01],\n",
            "          [-6.2195e-01, -4.1509e-01, -4.0200e-01,  ...,  1.9889e+00,\n",
            "           -1.4558e-01, -5.1420e-01]],\n",
            "\n",
            "         [[-5.0563e-01,  3.4884e-01, -4.0126e-01,  ...,  1.2945e+00,\n",
            "           -5.5872e-01, -4.4031e-01],\n",
            "          [-1.3903e+00, -1.6225e+00, -4.3093e-01,  ..., -9.2996e-02,\n",
            "            1.3483e+00, -8.6461e-01],\n",
            "          [-1.2555e+00, -1.3695e+00, -7.8693e-01,  ...,  1.6043e+00,\n",
            "            7.9744e-01,  8.3217e-02],\n",
            "          ...,\n",
            "          [-8.8294e-01,  8.9215e-01, -2.0276e+00,  ...,  4.6624e-01,\n",
            "            1.0873e+00, -3.3139e-01],\n",
            "          [-1.0021e+00, -1.6482e+00, -1.4811e+00,  ...,  1.3593e-01,\n",
            "            1.7498e+00,  7.7190e-01],\n",
            "          [-1.5350e+00, -4.3417e-01,  4.1296e-02,  ...,  9.4280e-01,\n",
            "            3.7350e-01, -5.4658e-01]],\n",
            "\n",
            "         [[ 1.3477e+00,  3.0343e+00,  3.7258e+00,  ...,  6.1286e-01,\n",
            "            1.7142e+00, -7.4960e-01],\n",
            "          [-3.4666e+00,  2.3726e+00, -3.5018e+00,  ..., -2.0312e+00,\n",
            "            3.0681e+00,  9.9892e-01],\n",
            "          [-3.2785e+00,  2.3944e+00, -4.0123e+00,  ..., -3.4514e+00,\n",
            "            3.5185e+00,  4.0514e-02],\n",
            "          ...,\n",
            "          [-4.3242e+00, -6.0702e+00, -4.5049e+00,  ..., -2.9650e+00,\n",
            "            9.8269e-01,  2.9467e+00],\n",
            "          [-2.9311e+00, -7.0744e+00, -5.4754e+00,  ..., -3.3435e+00,\n",
            "            5.2130e-01,  3.0629e+00],\n",
            "          [-2.0522e+00, -4.6360e+00, -3.0243e+00,  ..., -2.1969e+00,\n",
            "            2.1582e+00,  2.8623e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3818e+00, -2.7867e+00, -2.6519e+00,  ...,  9.1555e-01,\n",
            "            4.4077e-01,  2.7028e+00],\n",
            "          [-1.3913e+00,  1.6349e+00,  6.1729e-01,  ...,  1.5189e-02,\n",
            "           -1.9761e+00,  3.5912e-01],\n",
            "          [-2.3922e+00,  1.9435e+00,  8.9495e-01,  ..., -1.4562e+00,\n",
            "           -2.1497e+00, -2.6631e-01],\n",
            "          ...,\n",
            "          [-3.9238e+00,  6.4964e+00,  4.0557e+00,  ..., -2.4219e+00,\n",
            "           -4.4871e+00, -4.7536e+00],\n",
            "          [-3.8771e+00,  5.4078e+00,  4.6235e+00,  ..., -1.1688e+00,\n",
            "           -5.0280e+00, -5.4346e+00],\n",
            "          [-3.1867e+00,  4.6341e+00,  3.5179e+00,  ..., -5.6609e-01,\n",
            "           -2.0397e+00, -3.5643e+00]],\n",
            "\n",
            "         [[ 1.7415e+00,  4.5990e-01,  9.3163e-01,  ...,  1.2650e-03,\n",
            "           -9.8961e-01, -2.9552e-01],\n",
            "          [ 2.0667e+00,  1.2296e+00,  1.0938e+00,  ...,  5.0524e-01,\n",
            "           -1.4832e+00, -1.5294e+00],\n",
            "          [ 2.3246e+00,  1.3492e+00,  1.0889e+00,  ..., -7.8011e-02,\n",
            "           -9.2250e-01, -1.4462e+00],\n",
            "          ...,\n",
            "          [ 1.7695e+00, -2.2645e-02,  2.9717e-01,  ..., -2.1358e-01,\n",
            "           -2.1074e+00, -4.2575e-01],\n",
            "          [ 2.0812e+00, -2.8740e-01,  7.5142e-01,  ...,  2.5805e-01,\n",
            "           -1.3804e+00, -1.5495e-02],\n",
            "          [ 1.3602e+00,  1.1830e-01,  2.0696e-02,  ...,  3.9386e-01,\n",
            "           -1.9135e+00, -3.4978e-01]],\n",
            "\n",
            "         [[-2.2407e-01,  1.4293e-01, -5.5406e-01,  ...,  3.1676e-01,\n",
            "            2.7494e-01,  1.6436e-01],\n",
            "          [-8.8630e-01,  9.4746e-01, -2.6604e-01,  ...,  8.6753e-03,\n",
            "           -7.7659e-03,  3.1341e-01],\n",
            "          [-7.1774e-01,  1.3926e-01, -4.8629e-01,  ..., -3.3202e-01,\n",
            "            5.2814e-01,  3.8206e-01],\n",
            "          ...,\n",
            "          [ 1.1644e+00, -2.1901e-01,  4.0295e-02,  ...,  1.7840e-02,\n",
            "            3.3068e-01,  1.1496e-01],\n",
            "          [-6.4676e-01,  3.5059e-01, -4.3516e-01,  ..., -3.6649e-01,\n",
            "            5.5070e-01,  1.5234e-01],\n",
            "          [-8.8622e-01, -1.5089e-01, -6.2952e-01,  ...,  1.0692e+00,\n",
            "            5.5789e-01,  1.2183e+00]]]]), tensor([[[[-1.5059e-02, -2.1934e-02, -1.3257e-01,  ..., -3.3233e-03,\n",
            "            5.6872e-03, -5.5921e-01],\n",
            "          [ 1.2208e-01, -2.6165e-01, -5.3379e-01,  ..., -2.2557e-01,\n",
            "           -2.1276e-01,  3.1869e-01],\n",
            "          [-3.1618e-01, -4.9313e-01,  2.7285e-01,  ..., -2.9432e-01,\n",
            "            2.4368e-01,  4.9972e-01],\n",
            "          ...,\n",
            "          [-4.2372e-02,  2.5852e-01, -2.4844e-01,  ..., -9.9306e-03,\n",
            "           -1.7623e-01,  4.0643e-01],\n",
            "          [-4.6751e-01, -9.2778e-01,  6.9155e-01,  ..., -4.1175e-01,\n",
            "            1.1507e-01,  4.3020e-01],\n",
            "          [ 3.7920e-01,  1.2368e+00, -1.3722e+00,  ...,  4.3213e-01,\n",
            "            3.4956e-01, -1.2697e+00]],\n",
            "\n",
            "         [[ 3.8557e-02,  3.3663e-03,  5.4482e-02,  ..., -5.7578e-02,\n",
            "           -7.4123e-02,  2.2392e-02],\n",
            "          [-8.5546e-01, -2.1534e-02, -8.4275e-01,  ..., -5.7036e-01,\n",
            "            2.0840e-01, -2.3194e-01],\n",
            "          [ 1.7965e-01,  4.1504e-01, -6.0389e-01,  ..., -7.7887e-01,\n",
            "            4.4454e-01,  1.2518e-01],\n",
            "          ...,\n",
            "          [ 1.4460e-01,  5.0473e-01,  3.7954e-02,  ..., -9.8197e-02,\n",
            "            6.4722e-02,  6.3915e-02],\n",
            "          [-7.8309e-02,  1.0647e+00,  1.8167e-01,  ..., -1.7899e+00,\n",
            "            3.2821e-01, -6.8088e-01],\n",
            "          [-6.3497e-02,  1.4452e-01,  3.1524e-01,  ..., -6.7572e-01,\n",
            "           -9.8073e-02, -1.8497e-01]],\n",
            "\n",
            "         [[ 1.1201e-02, -7.6654e-01, -1.1584e-02,  ...,  4.3143e-02,\n",
            "            1.5736e-02, -5.8100e-02],\n",
            "          [ 1.5693e-01, -2.6265e-01,  2.1034e-01,  ..., -6.7786e-02,\n",
            "            1.3023e-01,  1.4455e-01],\n",
            "          [ 2.4833e-01, -1.2089e+00, -3.4619e-01,  ...,  2.5587e-01,\n",
            "           -1.5411e-01,  7.4661e-02],\n",
            "          ...,\n",
            "          [-4.5773e-01, -7.8409e-01, -5.4302e-01,  ..., -4.4201e-01,\n",
            "           -4.9519e-02, -2.1537e-01],\n",
            "          [ 1.4496e-01, -1.6216e+00, -8.2308e-02,  ...,  3.4291e-01,\n",
            "            2.8230e-01, -6.9510e-01],\n",
            "          [ 1.8964e-02, -1.2564e+00, -1.5367e-01,  ...,  2.5801e-02,\n",
            "            1.8990e-02,  1.9534e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6522e-02, -7.7326e-02,  1.3163e+00,  ..., -5.6423e-02,\n",
            "            1.7141e-01,  2.1386e-02],\n",
            "          [-1.9244e-01, -2.1685e-01,  1.8984e+00,  ...,  8.3269e-02,\n",
            "            2.8636e-01,  1.9398e-01],\n",
            "          [-5.7364e-01, -4.2843e-01,  1.8192e+00,  ...,  2.3323e-01,\n",
            "            5.1696e-01, -1.9490e-01],\n",
            "          ...,\n",
            "          [-2.9875e-01,  3.4439e-01,  2.5199e+00,  ...,  9.8624e-03,\n",
            "           -2.5633e-01, -6.4634e-02],\n",
            "          [ 3.0203e-02, -2.9376e-01,  1.7908e+00,  ..., -3.4844e-01,\n",
            "            3.6175e-01,  8.7788e-01],\n",
            "          [ 1.8360e-01, -2.7331e-01,  2.4081e+00,  ..., -1.3450e-01,\n",
            "            3.0442e-01, -1.7061e-02]],\n",
            "\n",
            "         [[ 7.4395e-02, -8.7165e-02, -1.8260e-01,  ...,  1.3185e-01,\n",
            "            1.2575e-01,  1.7169e-01],\n",
            "          [ 1.1488e+00,  1.9903e-01, -2.2611e-01,  ...,  6.5392e-01,\n",
            "           -3.8890e-01, -1.3570e-01],\n",
            "          [ 6.8785e-01,  5.5266e-01,  4.8935e-01,  ...,  5.0394e-01,\n",
            "           -4.9740e-01, -2.9491e-01],\n",
            "          ...,\n",
            "          [-7.1216e-01,  8.0623e-01,  4.5727e-01,  ...,  1.0620e+00,\n",
            "           -9.2505e-02, -6.2769e-01],\n",
            "          [ 3.7577e-01,  5.7647e-01, -4.9912e-02,  ..., -4.3928e-01,\n",
            "            5.5728e-02, -4.9533e-01],\n",
            "          [ 6.3871e-01,  9.9513e-01,  1.0109e-01,  ..., -5.7062e-02,\n",
            "            9.9612e-02,  5.4687e-01]],\n",
            "\n",
            "         [[ 1.1606e-02,  2.1828e-02,  2.7971e-02,  ..., -3.3218e-02,\n",
            "            2.2172e-01, -2.3344e-03],\n",
            "          [-3.5257e-01, -1.2851e-01, -1.8579e-01,  ..., -1.4255e-01,\n",
            "           -1.6637e+00,  3.2208e-01],\n",
            "          [-2.1173e-01, -6.1572e-01, -7.1549e-01,  ...,  2.9184e-01,\n",
            "           -2.0205e+00,  6.5390e-01],\n",
            "          ...,\n",
            "          [-1.9328e-01, -2.1982e-01,  1.5580e-01,  ...,  2.4489e-01,\n",
            "           -1.8665e+00, -2.4325e-01],\n",
            "          [ 4.6264e-01, -1.6466e-01, -3.6649e-01,  ..., -1.7379e-01,\n",
            "           -2.1945e+00, -3.4463e-01],\n",
            "          [ 1.9658e-01,  7.5329e-02,  6.6498e-02,  ..., -1.6416e-01,\n",
            "           -1.0588e+00,  5.8492e-02]]]])), (tensor([[[[ 0.0532, -0.2197,  0.1445,  ..., -0.8884,  0.7361, -1.2044],\n",
            "          [-1.0041, -1.0615, -0.6267,  ..., -0.4252, -0.3294, -0.3715],\n",
            "          [-0.0838, -0.7482, -0.0915,  ..., -0.7598, -0.1509,  0.5895],\n",
            "          ...,\n",
            "          [ 0.2528,  0.1196, -0.6958,  ...,  1.6861,  0.1134,  0.9358],\n",
            "          [ 1.4404,  1.5886, -3.0660,  ...,  0.4041, -0.8968,  0.7454],\n",
            "          [-0.4461, -0.7234, -0.2111,  ...,  1.0201,  0.0379,  0.3327]],\n",
            "\n",
            "         [[ 0.7842,  0.1905,  0.0089,  ..., -0.1612, -1.0898, -0.1939],\n",
            "          [-1.0430, -1.9451,  0.7810,  ...,  1.0171,  3.9617,  1.1669],\n",
            "          [-2.4692, -2.4786,  0.3021,  ..., -0.4223,  3.9857,  1.1009],\n",
            "          ...,\n",
            "          [ 1.0662, -0.4366, -0.9035,  ...,  0.1473,  6.5914,  1.5145],\n",
            "          [-1.0311,  0.6614, -0.2587,  ...,  0.1845,  6.1461,  0.3045],\n",
            "          [-1.9810,  0.8459, -0.9204,  ..., -0.2782,  3.2201,  1.6590]],\n",
            "\n",
            "         [[ 0.3413, -0.3572, -0.3331,  ...,  0.3294,  1.4604,  0.2755],\n",
            "          [-0.9062, -5.9880, -1.9177,  ..., -3.0968, -2.4686, -4.8798],\n",
            "          [-0.3773, -5.9712, -2.4314,  ..., -2.1100, -1.5185, -5.2938],\n",
            "          ...,\n",
            "          [-8.1241, -5.7790, -2.7704,  ..., -3.2832, -3.3692, -4.0502],\n",
            "          [-6.1515, -4.2803, -2.9422,  ..., -3.8752, -4.5318, -3.3472],\n",
            "          [-3.8523, -4.4674,  0.3345,  ..., -2.1369, -3.2997, -4.8551]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2148,  1.7719,  0.5129,  ...,  0.2612,  0.4477, -1.6895],\n",
            "          [-0.2691, -5.6503,  1.0538,  ..., -2.0220, -0.6386,  5.8947],\n",
            "          [ 1.2821, -7.0544,  1.7303,  ..., -1.2557,  0.1250,  4.9395],\n",
            "          ...,\n",
            "          [-0.1770, -8.3668, -0.4093,  ..., -4.4912, -4.5397,  7.5034],\n",
            "          [-1.3470, -7.3228, -2.2370,  ..., -2.2303, -3.7102,  6.9069],\n",
            "          [ 0.5593, -5.5251,  0.1979,  ..., -2.9406, -1.2177,  3.8345]],\n",
            "\n",
            "         [[ 0.0559, -0.0269,  0.1386,  ..., -0.1165, -0.0882, -0.1612],\n",
            "          [ 1.4347, -0.6062, -0.1794,  ..., -1.3716,  0.5309, -0.9923],\n",
            "          [-0.2935, -1.1905, -1.4349,  ..., -1.1824,  0.8352, -1.0368],\n",
            "          ...,\n",
            "          [-0.5604,  0.1355, -0.0762,  ..., -0.3239,  0.9390,  0.8627],\n",
            "          [ 0.0759, -0.1912, -1.3055,  ..., -0.9047,  0.7317, -0.3541],\n",
            "          [-0.1491, -0.9240, -0.3889,  ..., -0.1792, -0.0546, -0.1415]],\n",
            "\n",
            "         [[ 0.3939, -0.0741,  1.9091,  ..., -0.2314, -0.2112, -0.9825],\n",
            "          [ 2.4781,  2.0175, -1.7592,  ...,  1.6100,  1.5292,  1.9984],\n",
            "          [ 2.9344,  1.2111, -1.6720,  ...,  1.5815,  0.0603,  4.0486],\n",
            "          ...,\n",
            "          [ 1.7672, -0.2300, -3.1054,  ..., -0.8408,  2.2894,  4.9488],\n",
            "          [ 2.2490, -0.4260, -3.0040,  ...,  0.7549,  1.4083,  3.6302],\n",
            "          [ 1.4150,  0.7691, -2.8753,  ..., -1.8183,  0.5682,  3.1119]]]]), tensor([[[[ 0.0456,  0.0637, -0.0035,  ...,  0.0038,  0.1038,  0.0235],\n",
            "          [ 0.6593, -0.1335,  0.4165,  ...,  0.2357, -0.8313, -0.2563],\n",
            "          [ 0.2740, -0.0428,  0.3430,  ..., -0.3187, -0.3246, -1.3459],\n",
            "          ...,\n",
            "          [ 0.1218,  0.2250, -0.6774,  ...,  0.2193, -0.6206,  1.7828],\n",
            "          [-0.0347, -0.0351, -0.3752,  ..., -0.7976, -0.7495,  0.3969],\n",
            "          [-0.6547, -0.1719,  0.0143,  ..., -0.0590, -0.1387,  1.4553]],\n",
            "\n",
            "         [[-0.0390, -0.0086,  0.0916,  ..., -0.0451, -0.0183, -0.0445],\n",
            "          [ 0.1684, -0.0991,  0.4744,  ..., -0.0103, -0.0250,  0.0179],\n",
            "          [-0.3106,  0.1032,  0.0640,  ..., -0.4907,  0.3624, -0.5689],\n",
            "          ...,\n",
            "          [ 0.1756, -0.4911, -0.3374,  ...,  0.2176, -0.1871, -0.4651],\n",
            "          [ 0.0650, -0.8172, -0.3803,  ..., -0.0777,  0.7753, -0.1467],\n",
            "          [-0.5092,  0.0063,  0.0480,  ...,  0.2073, -0.3315, -0.4254]],\n",
            "\n",
            "         [[ 0.0458, -0.1111, -0.0603,  ..., -0.0173,  0.0884, -0.1492],\n",
            "          [-0.2184,  0.1298,  0.4800,  ...,  0.3039,  0.1771, -0.1179],\n",
            "          [-0.4607, -0.4118, -0.5156,  ..., -0.0549, -0.3311, -0.0158],\n",
            "          ...,\n",
            "          [-0.2995,  0.4172, -0.8152,  ..., -0.5647,  0.3652, -0.1091],\n",
            "          [-0.0828, -0.1201, -0.5991,  ...,  0.2276,  0.3839,  0.4508],\n",
            "          [ 0.1703,  0.0254, -0.8157,  ..., -0.1715, -0.0122, -0.3993]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0225,  0.1195, -0.0179,  ..., -0.0142,  0.0644, -0.0524],\n",
            "          [-0.3127,  0.5692, -0.6351,  ..., -0.6916,  0.3209,  0.2489],\n",
            "          [ 1.1410,  0.4432, -0.6404,  ...,  0.0162,  0.0658, -0.0260],\n",
            "          ...,\n",
            "          [ 0.0469, -0.2118,  0.4736,  ..., -0.6313,  0.0469, -0.4938],\n",
            "          [-0.3138, -0.0568,  0.1070,  ..., -0.2307,  0.3257,  0.0098],\n",
            "          [ 0.1383,  0.0996,  0.1049,  ...,  0.3356,  0.2591,  0.0923]],\n",
            "\n",
            "         [[-0.1737, -0.1341, -0.0678,  ..., -0.2352, -0.0187, -0.0519],\n",
            "          [ 0.7544, -1.5580,  0.2485,  ..., -0.0038,  0.8745,  0.9973],\n",
            "          [-0.2691, -0.8025,  0.3973,  ...,  0.4455, -0.7358,  0.2881],\n",
            "          ...,\n",
            "          [ 0.3787, -0.0891,  0.1144,  ...,  0.0984, -0.5767, -0.0277],\n",
            "          [-0.1750, -0.0376,  0.0485,  ...,  0.7765, -0.0328, -0.1504],\n",
            "          [ 0.2973,  0.3252,  0.2869,  ..., -0.5930, -0.6496,  0.0428]],\n",
            "\n",
            "         [[ 0.1148, -0.0748, -0.0254,  ..., -0.0187, -0.0913, -0.0969],\n",
            "          [ 0.7120,  0.1012, -0.2031,  ...,  0.6114,  0.4630, -0.0494],\n",
            "          [ 0.1013,  0.0055, -0.3748,  ...,  0.1937,  0.2171, -0.2702],\n",
            "          ...,\n",
            "          [ 0.5223,  0.1764,  0.3373,  ..., -0.3439, -0.1676, -0.1874],\n",
            "          [ 0.2232,  0.3738,  0.2423,  ..., -0.0918, -0.0218, -0.2175],\n",
            "          [ 0.6341, -0.1436,  0.0080,  ...,  0.0193, -0.5206,  0.0989]]]])), (tensor([[[[-8.8678e-01, -1.3593e-01,  3.3093e-01,  ..., -9.5576e-01,\n",
            "            2.5192e-02, -2.9464e+00],\n",
            "          [ 1.1123e+00,  8.3596e-01, -3.0617e+00,  ..., -3.3757e+00,\n",
            "           -7.5766e-01,  9.1512e+00],\n",
            "          [ 1.4312e+00, -8.3142e-01, -2.9655e+00,  ..., -3.3304e+00,\n",
            "           -5.4366e-01,  7.8222e+00],\n",
            "          ...,\n",
            "          [ 2.8498e-01, -3.4660e+00, -5.1799e-01,  ...,  1.6678e+00,\n",
            "           -2.7012e+00,  1.1903e+01],\n",
            "          [-5.2174e-01, -1.2861e+00, -1.6153e+00,  ...,  1.0838e+00,\n",
            "            4.5945e-01,  1.2836e+01],\n",
            "          [ 7.2257e-01,  1.7874e-01, -1.1297e+00,  ..., -7.0035e-01,\n",
            "           -5.8173e-01,  8.1148e+00]],\n",
            "\n",
            "         [[ 3.7499e-01, -6.6046e-02,  4.5773e-01,  ..., -1.2836e-01,\n",
            "           -7.7381e-02, -2.2161e+00],\n",
            "          [-2.5016e+00,  1.9264e-01,  3.1901e+00,  ..., -4.6352e-01,\n",
            "           -1.6780e+00,  8.0608e+00],\n",
            "          [-2.1704e+00,  7.0639e-01,  1.7289e+00,  ..., -8.2027e-01,\n",
            "           -2.7424e+00,  6.4781e+00],\n",
            "          ...,\n",
            "          [-1.5428e+00,  1.5942e+00,  2.7947e+00,  ..., -1.5249e+00,\n",
            "           -2.1040e+00,  4.1809e+00],\n",
            "          [-1.9820e+00,  1.1046e+00,  2.1078e+00,  ..., -1.9697e+00,\n",
            "           -9.6030e-01,  5.4648e+00],\n",
            "          [-1.6813e+00, -4.0830e-01,  2.5201e+00,  ..., -1.7389e-01,\n",
            "            7.0323e-02,  4.4771e+00]],\n",
            "\n",
            "         [[ 1.2211e-01, -6.5015e-01, -2.2831e-01,  ...,  1.4110e-01,\n",
            "            2.7893e-01, -1.7424e-01],\n",
            "          [-1.2324e-01,  2.3835e+00,  1.7934e-01,  ...,  1.1957e-01,\n",
            "            1.8070e-01,  3.9105e-01],\n",
            "          [-4.5130e-01,  1.7518e+00, -6.5570e-02,  ...,  8.2445e-01,\n",
            "           -8.1236e-01,  6.4083e-01],\n",
            "          ...,\n",
            "          [ 1.0136e+00,  3.5480e+00,  6.5907e-02,  ..., -1.6911e+00,\n",
            "            8.7774e-01, -1.9540e-01],\n",
            "          [ 2.1101e-01,  3.4189e+00,  2.8588e-01,  ..., -7.6371e-02,\n",
            "            1.0978e+00, -6.8433e-01],\n",
            "          [ 5.6244e-01,  2.0826e+00,  9.8865e-01,  ..., -9.2868e-01,\n",
            "            1.2578e+00, -2.7666e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0181e-01,  1.2737e-02, -1.1140e-02,  ...,  1.2548e+00,\n",
            "            4.3199e-02,  1.8033e+00],\n",
            "          [-9.1724e-02, -2.8112e+00,  1.4090e+00,  ..., -2.7210e+00,\n",
            "           -2.2742e+00, -6.4257e-01],\n",
            "          [ 4.5647e-01, -2.4431e+00,  2.6001e-01,  ..., -2.7358e+00,\n",
            "           -9.9958e-01, -3.3886e-02],\n",
            "          ...,\n",
            "          [ 9.1640e-01,  1.5164e+00,  1.2845e+00,  ..., -3.9465e+00,\n",
            "           -2.9445e-01, -2.3950e-01],\n",
            "          [ 3.4400e-01,  3.3188e-01,  5.2402e-01,  ..., -2.3971e+00,\n",
            "           -2.1131e-02, -8.0147e-01],\n",
            "          [ 1.2644e-01, -6.9866e-01, -1.5785e+00,  ..., -3.5413e+00,\n",
            "           -8.7817e-01, -9.4778e-01]],\n",
            "\n",
            "         [[-3.3790e-01, -1.2825e-01,  2.2242e-01,  ...,  2.6358e-01,\n",
            "           -2.9314e-02,  3.1528e-02],\n",
            "          [-1.2650e+00, -1.4965e-01,  8.7008e-01,  ..., -5.4157e-01,\n",
            "           -5.2848e-01, -5.6250e-01],\n",
            "          [-4.4942e-02, -1.5474e-01,  5.4156e-01,  ...,  1.0806e+00,\n",
            "            5.5058e-01, -5.0242e-01],\n",
            "          ...,\n",
            "          [ 5.8369e-01, -1.4556e+00,  2.1187e-01,  ...,  6.2665e-01,\n",
            "            1.7419e+00,  9.7168e-01],\n",
            "          [-3.7043e-01,  7.2937e-01, -1.9017e-01,  ...,  8.5298e-01,\n",
            "            1.2854e+00,  3.0978e+00],\n",
            "          [-7.7195e-01, -3.5189e-01,  1.1315e+00,  ...,  6.5264e-01,\n",
            "           -4.7713e-01,  1.6245e+00]],\n",
            "\n",
            "         [[ 3.4402e+00,  2.1226e+00, -2.1050e+00,  ..., -2.8555e+00,\n",
            "           -3.9038e+00, -1.2060e+00],\n",
            "          [-2.4996e+00, -2.0243e+00,  6.3698e+00,  ..., -2.3190e+00,\n",
            "            1.4067e+01, -1.3837e-01],\n",
            "          [-5.4002e+00, -1.8701e+00,  6.1426e+00,  ...,  7.0253e-01,\n",
            "            1.0042e+01, -1.0671e+00],\n",
            "          ...,\n",
            "          [-1.7726e+00, -1.0610e+00,  1.2282e+01,  ..., -1.7909e+00,\n",
            "            1.5164e+01,  3.5020e+00],\n",
            "          [ 2.6408e-01, -2.1446e+00,  1.3305e+01,  ..., -9.4526e-01,\n",
            "            1.3671e+01,  4.2504e+00],\n",
            "          [-3.3711e+00, -1.5098e+00,  9.1823e+00,  ...,  1.5725e+00,\n",
            "            1.0939e+01, -2.7958e-02]]]]), tensor([[[[-0.0028, -0.0602,  0.0219,  ...,  0.0593,  0.0264,  0.0681],\n",
            "          [ 0.0097, -0.1576,  0.4297,  ..., -0.3933, -0.1474,  0.4967],\n",
            "          [ 0.9463,  1.0042,  0.0165,  ...,  0.6791, -0.8171,  0.1032],\n",
            "          ...,\n",
            "          [ 0.2454, -0.1091,  0.0788,  ..., -0.7330, -0.1361,  0.1853],\n",
            "          [-0.6161, -0.2751,  0.4370,  ..., -0.5995, -0.0393, -0.1422],\n",
            "          [-0.1756, -0.0145, -0.1169,  ...,  0.0772, -0.0982,  0.1128]],\n",
            "\n",
            "         [[-0.0538, -0.0195, -0.1417,  ..., -0.0445,  0.0476, -0.0319],\n",
            "          [-0.1095,  0.3104, -0.4201,  ...,  0.1952,  0.0229,  0.3372],\n",
            "          [-0.6182,  0.2475,  0.2550,  ..., -0.1583,  0.1875,  0.6769],\n",
            "          ...,\n",
            "          [ 0.2742,  0.4129, -0.2897,  ..., -0.4656, -0.0035,  0.5858],\n",
            "          [-0.4335,  1.2169,  0.5454,  ..., -0.1701, -0.6893,  0.3983],\n",
            "          [-0.6355,  0.1615,  0.0203,  ..., -0.3279, -0.1453,  0.2094]],\n",
            "\n",
            "         [[ 0.0639,  0.0961,  0.0831,  ...,  0.0160, -0.0859, -0.0050],\n",
            "          [-1.2510, -0.5392, -1.0982,  ..., -0.3606, -0.3347,  0.2542],\n",
            "          [-0.5478, -0.1691,  0.4847,  ...,  1.0534,  1.0370, -1.1156],\n",
            "          ...,\n",
            "          [ 0.3405,  0.3000,  0.7465,  ...,  0.0899, -0.0499,  0.8850],\n",
            "          [-0.6840, -0.0421,  0.5419,  ...,  0.1050,  1.2876,  0.0972],\n",
            "          [-0.1612, -0.3889,  0.2498,  ...,  0.0526, -0.1446,  0.3576]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0115,  0.0657, -0.0777,  ...,  0.0440,  0.0456, -0.1384],\n",
            "          [ 0.5888, -0.0778,  0.3038,  ...,  0.2571,  0.0752,  1.1474],\n",
            "          [ 0.0650, -0.3550, -0.5290,  ...,  0.2673,  0.1990,  0.8943],\n",
            "          ...,\n",
            "          [ 0.6147,  0.4930, -0.0292,  ..., -0.0375, -0.0574, -0.3029],\n",
            "          [ 0.4827, -0.1818, -0.0409,  ..., -0.2861, -0.1620, -0.6373],\n",
            "          [-0.2753,  0.2716, -0.5314,  ...,  0.0923, -0.0455, -0.8216]],\n",
            "\n",
            "         [[-0.1315, -0.0534,  0.0947,  ..., -0.0666,  0.0539, -0.0204],\n",
            "          [-0.3001, -0.4590, -0.5426,  ...,  0.1423, -0.6356, -0.0379],\n",
            "          [-0.5016, -0.3376, -1.2072,  ..., -0.0115, -0.8030, -1.1322],\n",
            "          ...,\n",
            "          [ 0.0255, -0.1570, -1.1022,  ...,  0.7268, -1.1289, -0.5182],\n",
            "          [-0.2960, -1.0912, -1.9553,  ..., -0.4211,  0.1186, -0.6598],\n",
            "          [-0.1220, -0.3461,  0.0161,  ...,  0.2390, -0.4167, -0.7642]],\n",
            "\n",
            "         [[-0.0193, -0.0120, -0.0240,  ..., -0.0300,  0.0080, -0.0136],\n",
            "          [-0.1956,  0.4140,  0.1755,  ...,  0.2747, -0.0892, -0.4540],\n",
            "          [-0.3631, -0.1521, -0.2296,  ..., -0.3531, -0.5900,  0.4458],\n",
            "          ...,\n",
            "          [-0.4173,  0.3110,  0.0332,  ..., -0.5354,  0.1221,  0.2489],\n",
            "          [ 0.0754,  0.2000, -0.1923,  ..., -0.8863,  0.1182, -0.0568],\n",
            "          [ 0.5316, -0.0061, -0.0349,  ..., -0.4859, -0.1206,  0.2739]]]])), (tensor([[[[ 3.4512e-02, -2.8466e-01,  2.2210e-01,  ...,  1.6982e+00,\n",
            "           -2.2029e-01, -8.0207e-02],\n",
            "          [ 5.7606e-01,  1.3859e+00,  3.1709e-01,  ..., -2.7943e+00,\n",
            "            7.9149e-01, -7.8189e-01],\n",
            "          [ 1.8920e+00,  3.3602e-01,  2.0845e-01,  ..., -2.8536e+00,\n",
            "           -5.0251e-02, -1.0277e+00],\n",
            "          ...,\n",
            "          [ 1.1991e+00,  5.6499e-01, -5.8883e-02,  ..., -3.8401e+00,\n",
            "            1.2064e+00, -1.9923e+00],\n",
            "          [ 1.2130e+00,  2.6455e+00, -1.2965e-01,  ..., -4.6133e+00,\n",
            "           -7.3703e-02, -1.0455e+00],\n",
            "          [ 5.7909e-01,  1.7345e+00,  8.0802e-02,  ..., -3.5844e+00,\n",
            "           -3.9854e-01, -2.1912e-01]],\n",
            "\n",
            "         [[ 1.5566e-01,  9.6884e-01, -1.4234e+00,  ..., -1.1945e-01,\n",
            "            2.6095e-01,  9.2861e-01],\n",
            "          [-4.5351e-01, -4.9876e+00,  1.6253e+00,  ..., -1.2869e+00,\n",
            "           -2.7134e+00, -2.2154e+00],\n",
            "          [-8.7160e-02, -5.8149e+00,  2.0281e+00,  ..., -1.4027e+00,\n",
            "           -9.4778e-01, -4.2269e+00],\n",
            "          ...,\n",
            "          [ 2.4888e+00, -4.1862e+00,  6.6754e+00,  ...,  9.5650e-01,\n",
            "           -5.0533e-01, -4.5314e+00],\n",
            "          [ 3.0929e+00, -2.7240e+00,  3.9238e+00,  ...,  6.8633e-01,\n",
            "            2.2613e-01, -1.7745e+00],\n",
            "          [ 3.9084e+00, -3.7101e+00,  4.1582e+00,  ...,  9.3740e-01,\n",
            "            3.7293e-02, -2.2991e+00]],\n",
            "\n",
            "         [[-6.7068e-01,  2.4994e-01, -5.6570e-02,  ...,  1.7880e-01,\n",
            "            5.6148e-02, -2.9901e-01],\n",
            "          [ 2.6802e+00,  5.0060e-01, -6.6356e-01,  ..., -6.6714e-01,\n",
            "           -4.5204e-01,  6.2675e-01],\n",
            "          [ 3.2258e-01,  1.5204e-01, -1.5141e+00,  ..., -2.0511e+00,\n",
            "           -8.3181e-01, -1.1215e+00],\n",
            "          ...,\n",
            "          [ 2.1040e+00, -1.8531e+00, -5.6874e-01,  ...,  5.1320e-01,\n",
            "            9.8886e-01,  8.4752e-01],\n",
            "          [ 8.9416e-01, -1.2795e+00, -5.4282e-01,  ...,  1.3622e+00,\n",
            "            2.1435e+00,  6.9565e-01],\n",
            "          [ 7.1458e-01,  1.3794e-01, -6.4344e-01,  ..., -1.2585e+00,\n",
            "           -8.5104e-01,  9.1952e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0635e-02,  1.1188e-01,  1.4037e-01,  ..., -9.7647e-02,\n",
            "            1.2961e-02,  1.5000e-01],\n",
            "          [ 1.3441e+00, -8.1234e-01, -6.8176e-01,  ...,  8.0431e-01,\n",
            "           -2.8690e-01,  2.3457e-02],\n",
            "          [ 9.0540e-01, -7.4102e-01, -5.2534e-01,  ...,  9.9180e-01,\n",
            "           -9.3895e-01,  6.9476e-01],\n",
            "          ...,\n",
            "          [-5.2056e-01,  7.2703e-01, -1.0235e+00,  ...,  1.1114e+00,\n",
            "            7.8265e-01,  1.6925e+00],\n",
            "          [ 3.3979e-01, -4.2525e-02,  5.8028e-01,  ...,  1.7633e+00,\n",
            "            2.7698e-01,  6.5836e-01],\n",
            "          [ 8.4962e-01, -9.3584e-01, -7.6607e-03,  ...,  1.0660e+00,\n",
            "            2.2574e-01,  2.5772e-01]],\n",
            "\n",
            "         [[-3.0020e+00,  4.0418e-01, -2.7798e-02,  ..., -4.8566e-01,\n",
            "           -3.4500e-01,  1.2311e+00],\n",
            "          [ 4.3624e+00,  2.5905e-01, -1.4339e+00,  ..., -7.6012e-02,\n",
            "            9.6264e-01,  6.3543e-01],\n",
            "          [ 4.5551e+00, -9.7941e-01,  2.5921e-01,  ..., -8.3005e-01,\n",
            "            2.0203e+00,  7.2641e-02],\n",
            "          ...,\n",
            "          [ 5.7926e+00, -9.8910e-01, -7.6052e-01,  ..., -5.0502e-01,\n",
            "           -4.6244e-01,  2.4139e-01],\n",
            "          [ 5.9805e+00,  6.0374e-01, -4.4615e-01,  ..., -4.8976e-01,\n",
            "           -3.4905e-01, -2.4499e-01],\n",
            "          [ 4.2451e+00,  3.9808e-01, -1.0405e+00,  ..., -1.9134e+00,\n",
            "            2.8083e-01,  1.1580e+00]],\n",
            "\n",
            "         [[-7.4442e-03, -2.5452e-01, -1.9920e-04,  ..., -1.8494e-01,\n",
            "            3.4208e-01,  9.0523e-02],\n",
            "          [ 1.3662e-02, -1.9992e+00,  4.6807e-01,  ..., -2.8424e-01,\n",
            "           -4.5969e-02, -4.9747e-01],\n",
            "          [-7.9128e-01, -1.5962e+00, -2.8448e-01,  ..., -5.4482e-01,\n",
            "            9.8224e-01,  4.5007e-01],\n",
            "          ...,\n",
            "          [-9.7629e-01, -4.2305e-01,  1.1298e+00,  ..., -5.4101e-01,\n",
            "            1.2183e+00, -6.6479e-01],\n",
            "          [ 8.6665e-01, -2.0267e+00,  5.7736e-01,  ..., -5.4657e-01,\n",
            "            8.8251e-01,  8.0152e-02],\n",
            "          [-7.0469e-02, -1.4979e+00,  1.5815e-01,  ..., -1.1323e-01,\n",
            "            2.3559e-01,  1.1617e-01]]]]), tensor([[[[-2.2352e-02, -2.3890e-02,  3.0800e-03,  ..., -2.7138e-03,\n",
            "           -2.0931e-02,  3.5350e-01],\n",
            "          [ 2.1707e+00, -3.8869e-01,  8.2946e-02,  ..., -1.8298e-01,\n",
            "           -2.7244e-01, -1.0429e+00],\n",
            "          [ 1.4542e+00,  6.2451e-01,  1.3032e+00,  ...,  5.1255e-01,\n",
            "            6.4256e-01, -1.4007e+00],\n",
            "          ...,\n",
            "          [-7.5302e-01, -1.5922e+00, -5.4117e-01,  ..., -2.6317e-01,\n",
            "           -3.3939e-01,  1.4489e-01],\n",
            "          [-1.0745e-01, -3.7070e-01,  6.1868e-01,  ...,  4.2690e-01,\n",
            "            4.8766e-03, -6.9716e-01],\n",
            "          [-1.3591e-01, -4.1555e-02, -3.5403e-01,  ...,  6.3506e-01,\n",
            "           -4.0891e-02, -6.0055e-01]],\n",
            "\n",
            "         [[ 4.7504e-03, -1.6114e-02,  1.8607e-02,  ..., -1.4957e-02,\n",
            "            1.4970e-02,  9.0305e-03],\n",
            "          [ 1.0151e+00,  6.6067e-01, -4.5352e-01,  ..., -1.6398e-01,\n",
            "            7.8373e-01,  8.6147e-02],\n",
            "          [ 2.7414e-01,  4.2059e-02,  8.4587e-01,  ..., -2.9318e-01,\n",
            "            9.4665e-01, -1.1619e+00],\n",
            "          ...,\n",
            "          [ 3.4050e-01, -1.5817e+00, -1.5986e-01,  ...,  2.4432e-02,\n",
            "            3.5290e-01, -2.8193e-01],\n",
            "          [ 1.5573e+00, -2.8593e-01, -4.4057e-03,  ..., -2.6060e-01,\n",
            "           -2.0641e-01, -1.3527e+00],\n",
            "          [-2.5449e-01, -6.4861e-01, -1.1086e+00,  ..., -1.6675e-01,\n",
            "            1.0872e+00, -1.4692e+00]],\n",
            "\n",
            "         [[-6.0323e-02,  3.0277e-03, -3.8265e-02,  ..., -4.6841e-02,\n",
            "            1.1918e-02, -7.8043e-02],\n",
            "          [ 8.9248e-01, -1.1489e+00,  8.0415e-01,  ...,  1.4875e-01,\n",
            "           -2.4802e-01, -2.3914e-01],\n",
            "          [-2.0760e-02,  3.2928e-02,  9.7039e-01,  ..., -4.9037e-01,\n",
            "            7.1658e-01, -2.0370e-01],\n",
            "          ...,\n",
            "          [ 1.5928e+00,  2.7020e-01, -2.4713e-01,  ...,  9.1223e-01,\n",
            "            5.4889e-01,  4.8028e-01],\n",
            "          [ 4.0539e-01, -8.6129e-02, -4.6525e-01,  ..., -1.0141e+00,\n",
            "            6.2955e-01, -4.9422e-01],\n",
            "          [ 8.2649e-01,  8.9075e-02,  9.7400e-01,  ...,  2.1022e-01,\n",
            "            7.4409e-01,  2.0249e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0629e-01, -1.9044e-01, -5.3980e-02,  ..., -4.8476e-01,\n",
            "            2.1315e-01,  1.0492e-01],\n",
            "          [ 1.0915e+00, -1.8013e+00,  1.2444e+00,  ...,  1.3759e+00,\n",
            "           -1.3736e-01, -3.6652e-01],\n",
            "          [ 1.8101e+00, -3.0727e+00, -1.0736e-01,  ...,  4.8768e-01,\n",
            "           -2.2441e+00, -3.3691e-01],\n",
            "          ...,\n",
            "          [ 1.1489e+00, -1.7199e+00, -2.1945e-01,  ...,  2.0704e+00,\n",
            "            2.6888e+00, -5.8468e-01],\n",
            "          [ 7.3884e-01, -5.1338e-01, -3.3193e-01,  ...,  2.7250e+00,\n",
            "            1.2588e+00, -3.1618e-01],\n",
            "          [ 1.9944e+00, -1.2571e+00, -7.0450e-01,  ...,  7.7175e-01,\n",
            "            2.0023e-01,  8.5725e-01]],\n",
            "\n",
            "         [[-8.6142e-02, -1.4120e-01, -5.3430e-02,  ..., -1.7972e-01,\n",
            "           -1.4655e-01,  1.1416e-01],\n",
            "          [-4.1986e-02,  1.0996e-01, -3.0338e-01,  ..., -7.9631e-02,\n",
            "            8.6960e-03, -3.4344e-01],\n",
            "          [-6.9500e-01, -6.0030e-02, -1.3937e-01,  ...,  5.4800e-01,\n",
            "            8.3420e-01,  4.1376e-01],\n",
            "          ...,\n",
            "          [-1.3747e-01,  5.0311e-01, -6.1817e-01,  ...,  1.4209e-02,\n",
            "            8.0600e-01,  3.0534e-01],\n",
            "          [ 2.6711e-01,  7.9022e-01, -1.5137e+00,  ...,  6.9212e-01,\n",
            "            5.5454e-01,  9.9380e-01],\n",
            "          [-6.5464e-01, -9.1091e-02, -4.9255e-01,  ...,  8.3130e-01,\n",
            "            5.0163e-01,  5.2870e-01]],\n",
            "\n",
            "         [[-2.9444e-02, -4.1441e-02,  1.0690e-01,  ...,  6.1366e-02,\n",
            "           -4.1197e-02,  2.3883e-02],\n",
            "          [-3.1227e-01, -3.4491e-01, -6.5569e-01,  ..., -8.2047e-01,\n",
            "           -1.0168e+00,  4.5567e-01],\n",
            "          [-4.0689e-02, -5.5587e-01, -1.5327e+00,  ..., -4.5555e-01,\n",
            "           -4.0282e-01,  1.5587e-01],\n",
            "          ...,\n",
            "          [-4.1874e-01, -4.5857e-01, -3.6130e-01,  ...,  1.0674e+00,\n",
            "            7.5678e-01,  3.3775e-01],\n",
            "          [-1.3045e+00, -1.5805e+00,  4.9256e-01,  ...,  6.5934e-01,\n",
            "            9.8726e-01,  1.4015e+00],\n",
            "          [-4.6301e-01, -8.8778e-01, -3.3827e-01,  ...,  3.9314e-01,\n",
            "            4.8873e-01,  6.7418e-01]]]])), (tensor([[[[-3.3938e-01,  8.6866e-01, -1.6351e-01,  ...,  1.1267e+00,\n",
            "           -1.6784e-01,  1.2959e-01],\n",
            "          [ 7.8966e-01, -4.3158e+00,  8.9523e-03,  ..., -3.4318e+00,\n",
            "           -3.5352e-01,  1.2415e+00],\n",
            "          [-1.1423e-01, -4.7016e+00, -9.0370e-01,  ..., -3.7405e+00,\n",
            "            9.0388e-01,  1.6338e+00],\n",
            "          ...,\n",
            "          [ 5.4643e-01, -1.6046e+00,  4.4830e+00,  ..., -5.2096e+00,\n",
            "           -2.7472e-01,  1.3851e+00],\n",
            "          [ 1.1656e+00, -3.5129e+00,  2.0187e+00,  ..., -5.0405e+00,\n",
            "           -3.9071e-01, -7.8250e-01],\n",
            "          [-6.0249e-01, -3.1750e+00,  8.0649e-01,  ..., -4.7813e+00,\n",
            "            9.8501e-01,  1.2058e-01]],\n",
            "\n",
            "         [[ 5.8217e-02,  8.7121e-01, -6.2251e-01,  ..., -2.4310e-02,\n",
            "            2.9330e-01,  1.3199e-02],\n",
            "          [ 2.4821e-01, -6.4453e-01,  7.7931e-01,  ...,  3.7043e-01,\n",
            "            6.1201e-01, -1.3439e+00],\n",
            "          [-1.0082e+00,  1.8812e-01,  2.4814e+00,  ...,  4.1480e-01,\n",
            "           -2.2177e-01, -6.0108e-01],\n",
            "          ...,\n",
            "          [-1.1003e+00, -3.9877e-01,  1.0265e+00,  ...,  7.9258e-02,\n",
            "            2.6356e+00, -1.7822e+00],\n",
            "          [-5.0960e-01,  1.4210e-01,  1.9715e+00,  ...,  6.5371e-01,\n",
            "            3.4577e+00, -1.7795e+00],\n",
            "          [ 2.9718e-01,  2.7300e-01,  1.7083e+00,  ...,  1.0533e+00,\n",
            "            1.1595e+00, -6.1935e-01]],\n",
            "\n",
            "         [[-3.1165e-01,  1.2165e-01, -9.8370e-01,  ..., -3.5095e-01,\n",
            "           -6.3912e-02, -1.3616e-01],\n",
            "          [ 2.0441e-02, -1.0382e+00,  3.5401e+00,  ...,  7.7515e-01,\n",
            "           -1.8138e-01,  8.1544e-02],\n",
            "          [ 2.3739e-01, -5.6998e-01,  4.2453e+00,  ...,  1.7163e-01,\n",
            "           -2.6420e-01, -8.6268e-01],\n",
            "          ...,\n",
            "          [-3.4149e-01,  1.3542e+00,  4.1141e+00,  ..., -8.4710e-01,\n",
            "           -2.2100e-02, -1.2756e+00],\n",
            "          [-1.2585e+00, -1.1703e+00,  3.5780e+00,  ...,  6.1419e-01,\n",
            "           -8.5867e-01, -3.7232e-01],\n",
            "          [ 1.1154e-01, -1.8309e-01,  2.3530e+00,  ..., -2.0560e-02,\n",
            "           -1.2480e+00,  2.0519e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7597e-01,  8.1398e-02, -6.4505e-02,  ..., -4.8594e-02,\n",
            "            2.2536e-01,  4.1932e-03],\n",
            "          [-1.5684e+00,  7.0856e-01, -5.4626e-01,  ...,  2.8057e-01,\n",
            "            1.7972e-02, -9.1632e-01],\n",
            "          [-8.5027e-01, -9.3106e-01,  1.9188e+00,  ..., -8.2132e-01,\n",
            "           -5.1166e-02,  4.2851e-01],\n",
            "          ...,\n",
            "          [-1.6419e+00,  1.6395e+00,  2.8496e-01,  ...,  2.5064e+00,\n",
            "            1.3195e+00,  1.2866e+00],\n",
            "          [-1.6818e+00, -2.7695e-01, -3.1605e-01,  ..., -2.3483e-01,\n",
            "            5.2715e-01,  4.1755e-01],\n",
            "          [-1.3257e+00,  4.8860e-01,  5.4499e-01,  ..., -5.0974e-01,\n",
            "           -2.6145e-02,  1.1548e+00]],\n",
            "\n",
            "         [[ 2.0009e-01,  5.4941e-02,  3.2748e-01,  ...,  4.1661e-01,\n",
            "           -3.4165e-03,  2.3171e-01],\n",
            "          [ 1.6548e+00,  7.3752e-01, -1.4867e-01,  ..., -8.9941e-01,\n",
            "           -1.8640e-01,  9.6849e-01],\n",
            "          [ 1.8403e+00, -1.2025e-01,  1.6515e-01,  ..., -1.3440e+00,\n",
            "           -1.8950e-01,  1.0828e+00],\n",
            "          ...,\n",
            "          [ 2.1230e-01, -2.3706e+00,  1.0028e+00,  ..., -5.5337e-01,\n",
            "           -4.4323e-01,  9.5999e-01],\n",
            "          [ 1.4036e+00, -1.0607e+00,  6.3097e-01,  ..., -1.0458e-01,\n",
            "           -1.3551e+00,  2.0284e+00],\n",
            "          [ 2.3459e+00, -1.3236e+00,  2.5462e-01,  ...,  2.6987e-01,\n",
            "           -3.8448e-01,  1.7128e+00]],\n",
            "\n",
            "         [[-3.0156e+00,  5.3756e-01,  5.6815e-01,  ..., -9.3899e-01,\n",
            "            3.2683e-01,  1.8463e-01],\n",
            "          [ 7.6085e+00, -1.5877e+00, -1.1030e+00,  ...,  1.8897e+00,\n",
            "            4.0041e-01, -7.4572e-02],\n",
            "          [ 7.7662e+00, -8.5829e-01, -2.2388e+00,  ...,  1.3556e+00,\n",
            "           -1.7786e-01,  3.1814e-01],\n",
            "          ...,\n",
            "          [ 8.3342e+00, -2.7379e+00, -9.0413e-01,  ..., -6.5594e-02,\n",
            "            5.8657e-01, -9.6635e-01],\n",
            "          [ 1.0916e+01, -2.7868e+00, -2.5319e+00,  ..., -2.1118e-01,\n",
            "           -2.5398e-01, -1.3262e+00],\n",
            "          [ 8.3424e+00, -1.0773e+00, -1.5246e-01,  ...,  2.9722e+00,\n",
            "           -1.6784e-01, -9.5830e-01]]]]), tensor([[[[ 4.6474e-02, -5.0378e-02,  1.0945e-02,  ..., -6.9955e-02,\n",
            "            2.9789e-03, -1.0073e-01],\n",
            "          [ 2.0177e-01, -9.9374e-02, -4.6054e-01,  ..., -7.7444e-01,\n",
            "           -2.7597e-01,  5.7921e-02],\n",
            "          [ 4.9510e-01,  3.8586e-01, -7.6936e-01,  ..., -1.1830e+00,\n",
            "           -1.8249e-03,  9.3978e-03],\n",
            "          ...,\n",
            "          [-5.1577e-01, -3.5346e-02, -7.2292e-01,  ...,  6.1683e-01,\n",
            "            7.7100e-01,  1.8441e-01],\n",
            "          [-2.2705e-01,  5.1722e-01, -8.6228e-01,  ...,  2.6447e-01,\n",
            "            8.9092e-01, -1.6183e-01],\n",
            "          [ 1.6851e-01,  1.5246e-02, -4.9478e-01,  ...,  3.2312e-01,\n",
            "            5.3880e-01, -8.4478e-01]],\n",
            "\n",
            "         [[ 6.7674e-02,  3.0544e-02, -2.3115e-02,  ..., -4.3823e-02,\n",
            "            5.2574e-03, -1.6795e-03],\n",
            "          [ 7.4404e-01,  1.0953e+00, -6.2701e-01,  ..., -3.8431e-01,\n",
            "            1.8351e-01,  6.4869e-01],\n",
            "          [ 5.3132e-01,  6.3413e-01,  8.0079e-01,  ...,  1.0831e+00,\n",
            "            9.9377e-01, -7.9643e-01],\n",
            "          ...,\n",
            "          [ 3.8110e-01,  1.0590e+00,  7.7399e-01,  ...,  1.5494e-01,\n",
            "            5.0788e-01,  5.9110e-01],\n",
            "          [ 1.9339e-01, -4.0536e-01,  1.2820e+00,  ..., -1.3346e+00,\n",
            "           -4.7700e-01,  4.9724e-01],\n",
            "          [ 7.0294e-01,  2.0657e-01,  6.7153e-01,  ..., -5.9957e-01,\n",
            "            2.8928e-01,  4.5207e-01]],\n",
            "\n",
            "         [[ 7.0952e-02,  8.2320e-03, -1.6572e-03,  ...,  2.1678e-02,\n",
            "           -6.7437e-02, -5.0287e-02],\n",
            "          [ 5.7295e-01,  8.2618e-02, -2.2721e-01,  ..., -4.8598e-01,\n",
            "            5.1604e-01,  6.3336e-01],\n",
            "          [-4.8793e-01, -4.2573e-01,  1.8884e-01,  ..., -1.3981e+00,\n",
            "            1.1536e+00,  2.4069e-01],\n",
            "          ...,\n",
            "          [ 6.6456e-01,  8.8502e-01, -4.2509e-01,  ..., -1.9884e+00,\n",
            "           -5.9137e-02, -1.0077e+00],\n",
            "          [-5.8014e-01,  1.3552e+00, -1.7615e+00,  ..., -2.1724e+00,\n",
            "            7.4639e-01, -3.6454e-02],\n",
            "          [ 2.6255e-01,  1.8527e-01, -3.4899e-01,  ..., -1.0471e+00,\n",
            "            1.2051e+00, -8.7104e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.4018e-04,  4.2945e-02,  2.0029e-02,  ..., -6.6209e-02,\n",
            "           -1.8070e-02,  2.2869e-02],\n",
            "          [-1.0373e+00, -8.3779e-01, -3.9356e-01,  ...,  6.9054e-01,\n",
            "            8.7881e-01, -8.3498e-02],\n",
            "          [-7.5369e-01,  2.9458e-01, -9.3436e-01,  ..., -4.1765e-01,\n",
            "            7.9852e-02,  1.5722e+00],\n",
            "          ...,\n",
            "          [ 1.7772e-01, -1.2248e+00, -8.4567e-01,  ...,  1.0436e-01,\n",
            "           -1.4694e+00,  9.5464e-01],\n",
            "          [ 8.0011e-01,  1.5801e+00, -2.7669e-01,  ..., -1.3910e+00,\n",
            "           -5.7459e-01, -4.7304e-01],\n",
            "          [ 2.9241e-01, -8.9908e-01, -4.8790e-02,  ..., -3.1947e-05,\n",
            "            1.0902e+00,  1.1298e+00]],\n",
            "\n",
            "         [[ 5.6418e-02, -6.3642e-03,  2.3703e-02,  ...,  1.7139e-02,\n",
            "           -1.5312e-02,  6.8113e-03],\n",
            "          [ 9.7107e-02,  7.4083e-01, -9.1236e-01,  ...,  3.1117e-01,\n",
            "           -1.2195e+00,  8.9329e-02],\n",
            "          [-4.1569e-01,  3.8381e-01, -2.6367e-01,  ...,  1.5020e-01,\n",
            "           -3.2388e-01,  1.2846e-01],\n",
            "          ...,\n",
            "          [-1.4727e-01,  6.5225e-02, -7.7421e-01,  ..., -9.6231e-02,\n",
            "           -7.0351e-01,  7.1229e-02],\n",
            "          [ 1.6206e+00,  7.0055e-01, -3.9221e-01,  ...,  3.6796e-01,\n",
            "            9.6290e-02,  7.3975e-01],\n",
            "          [-2.4605e-02, -2.0795e-01, -8.1133e-01,  ...,  5.4694e-01,\n",
            "           -3.3072e-01,  1.3258e-01]],\n",
            "\n",
            "         [[ 6.7269e-02, -2.0375e-01, -7.5082e-02,  ..., -4.0162e-02,\n",
            "            1.9610e-01, -5.1942e-02],\n",
            "          [-5.2712e-01, -1.4517e+00, -6.1562e-01,  ..., -2.5019e-01,\n",
            "           -2.1741e-01,  4.3261e-01],\n",
            "          [ 3.0705e-01,  3.1797e-01, -1.1217e+00,  ...,  9.0373e-01,\n",
            "           -9.4850e-01, -4.9656e-01],\n",
            "          ...,\n",
            "          [ 5.8118e-01,  9.4711e-01,  9.0790e-01,  ..., -1.7492e+00,\n",
            "           -2.6849e-01, -5.2167e-01],\n",
            "          [-6.1444e-01, -5.3170e-01,  6.2132e-03,  ..., -7.8775e-01,\n",
            "           -5.5870e-02, -1.3294e-01],\n",
            "          [-8.8363e-01, -1.2704e+00, -6.1780e-01,  ..., -7.4162e-01,\n",
            "           -3.1949e-01,  1.9272e-01]]]])), (tensor([[[[ 1.0315, -0.2591, -0.1501,  ...,  0.6246,  0.7232, -0.3059],\n",
            "          [-3.2604, -1.8197,  0.0272,  ...,  1.3174, -5.1837, -0.3084],\n",
            "          [-3.0370, -1.9140,  1.1994,  ..., -0.1186, -4.0171,  0.6810],\n",
            "          ...,\n",
            "          [-6.5947, -3.0807,  0.6317,  ...,  3.1697, -4.8478,  0.3262],\n",
            "          [-5.8169, -3.3575, -0.7244,  ...,  0.7595, -4.0161, -1.4850],\n",
            "          [-4.3148, -1.5532, -1.4597,  ..., -0.7701, -2.9604,  0.3281]],\n",
            "\n",
            "         [[-0.1525, -0.0745,  0.1651,  ..., -0.0464, -0.8761, -0.1921],\n",
            "          [-1.1519,  1.1435, -0.7256,  ..., -0.1296,  0.8282,  2.6677],\n",
            "          [-1.7338,  0.6964,  0.5820,  ..., -0.2579,  1.1376,  0.8273],\n",
            "          ...,\n",
            "          [-0.7464,  1.0029, -1.3744,  ..., -0.2273,  1.8539,  1.4021],\n",
            "          [-0.4790,  1.2135, -1.8628,  ..., -0.4278,  0.2788,  0.9853],\n",
            "          [-2.1823,  0.3044, -0.3986,  ...,  0.3907,  0.6538,  0.2638]],\n",
            "\n",
            "         [[ 0.1958,  0.3039,  1.1389,  ..., -0.4691,  0.4513, -0.4878],\n",
            "          [-2.2374, -1.3085, -0.8322,  ..., -0.0724, -1.1114,  2.3614],\n",
            "          [-2.3158,  0.3386,  0.3405,  ..., -1.0796, -1.9980,  1.0447],\n",
            "          ...,\n",
            "          [-2.2771, -2.0891,  0.2349,  ..., -1.7714, -1.3030,  3.6295],\n",
            "          [-0.2526, -1.9873,  0.2215,  ..., -3.4028, -0.8980,  4.9316],\n",
            "          [-0.1722,  0.6679,  0.0428,  ..., -1.4102, -1.7271,  3.0315]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1518,  0.0675, -0.2341,  ...,  0.0125,  0.1685,  0.0227],\n",
            "          [-2.1834,  0.2617, -0.6221,  ...,  1.2776, -0.3134, -0.6763],\n",
            "          [-1.7372,  0.4356, -1.1103,  ..., -0.1356, -0.4766, -0.6605],\n",
            "          ...,\n",
            "          [ 0.3963,  1.9169,  1.9014,  ...,  0.4851,  0.2138,  1.4487],\n",
            "          [-2.2355,  1.2745,  1.2059,  ...,  1.0578,  1.2899, -0.4830],\n",
            "          [-1.6264,  1.5092, -1.1613,  ..., -0.1062,  0.5215, -0.4830]],\n",
            "\n",
            "         [[-0.3515, -2.1836,  0.1103,  ..., -0.0873, -0.0481,  0.9174],\n",
            "          [-0.9330,  2.7194, -0.5069,  ..., -1.0633, -1.7080,  1.2813],\n",
            "          [-0.0570,  3.7499, -1.3886,  ...,  0.0306, -1.3732,  0.8404],\n",
            "          ...,\n",
            "          [-1.5283,  5.9363, -3.0117,  ..., -1.2823, -1.9315, -0.6259],\n",
            "          [-0.1088,  3.7593, -1.4645,  ...,  1.0016, -1.6663,  2.1726],\n",
            "          [-0.9069,  1.1764, -1.1956,  ...,  0.8535, -1.6704,  1.4523]],\n",
            "\n",
            "         [[ 0.3682,  0.0657, -0.1320,  ...,  0.6454,  0.1343,  0.2644],\n",
            "          [-0.4719, -0.4074, -0.2126,  ..., -0.4719, -0.0214, -1.0250],\n",
            "          [-1.3249, -0.5722,  0.7829,  ..., -0.7093,  0.4608,  0.5007],\n",
            "          ...,\n",
            "          [-2.6329, -0.3120, -0.2158,  ..., -1.3975, -1.0142, -1.8848],\n",
            "          [-2.4493,  0.7973, -0.9755,  ...,  0.0962, -1.0788, -0.3618],\n",
            "          [-1.7438,  0.9637,  0.7875,  ..., -0.2884,  0.2079, -0.0408]]]]), tensor([[[[-2.8336e-02,  4.5010e-02, -5.7978e-02,  ..., -1.9222e-02,\n",
            "            1.2577e-02,  3.6269e-02],\n",
            "          [-3.6785e-01, -9.6275e-01, -2.6915e-01,  ..., -4.7552e-01,\n",
            "            6.9057e-01,  1.1659e-01],\n",
            "          [-3.9534e-01, -3.4020e-01, -8.9255e-01,  ...,  2.4867e-01,\n",
            "            7.2389e-01, -3.6358e-02],\n",
            "          ...,\n",
            "          [-2.2336e-01, -6.7906e-01, -4.1274e-01,  ...,  1.3097e+00,\n",
            "           -2.8501e-01, -4.2783e-01],\n",
            "          [-4.2270e-01, -1.9808e-01, -5.6371e-01,  ...,  8.0854e-02,\n",
            "            4.4483e-01, -3.3069e-01],\n",
            "          [-8.5640e-01,  1.2059e-01, -2.4266e-01,  ..., -1.3635e-01,\n",
            "            4.4968e-01, -1.0662e-01]],\n",
            "\n",
            "         [[ 2.1536e-02, -2.8120e-02,  3.8532e-02,  ...,  2.1765e-02,\n",
            "           -4.7212e-02,  5.3255e-03],\n",
            "          [ 6.5257e-02, -9.2366e-01, -7.7179e-02,  ...,  6.7124e-01,\n",
            "           -2.1939e-01, -3.5770e-01],\n",
            "          [-3.1066e-01,  1.6781e-01,  4.8579e-01,  ..., -1.5019e-01,\n",
            "            1.5135e+00, -6.7904e-01],\n",
            "          ...,\n",
            "          [-1.5217e+00, -5.8569e-01, -3.7776e-01,  ..., -1.1823e-01,\n",
            "            8.4007e-01,  1.7017e-01],\n",
            "          [-5.6865e-01,  1.5059e+00, -1.4678e+00,  ..., -2.6174e-01,\n",
            "            6.6757e-01,  2.7148e-01],\n",
            "          [ 1.4829e-01,  7.5766e-01, -6.4790e-01,  ..., -6.4620e-01,\n",
            "            1.0936e+00, -4.8857e-01]],\n",
            "\n",
            "         [[ 3.9084e-02, -2.6990e-02,  5.6189e-02,  ...,  2.6549e-02,\n",
            "           -7.1806e-03,  1.9065e-02],\n",
            "          [-7.5893e-01,  1.4084e+00, -2.0681e-01,  ...,  7.8902e-01,\n",
            "           -8.0951e-01,  1.2339e+00],\n",
            "          [-3.2406e-01, -3.2491e-01,  5.3352e-01,  ...,  1.0467e+00,\n",
            "            5.5796e-01, -4.9593e-01],\n",
            "          ...,\n",
            "          [ 3.4416e-01, -2.7680e-01, -8.3116e-01,  ...,  2.2781e+00,\n",
            "           -5.5173e-01, -1.4375e-02],\n",
            "          [-1.9603e-01,  4.3127e-01, -2.0240e-01,  ..., -3.8622e-01,\n",
            "            2.6178e-01,  2.2390e-01],\n",
            "          [-1.8365e-01,  1.0350e-01, -1.1408e-01,  ..., -2.4412e+00,\n",
            "            2.2784e-01,  3.1796e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8650e-01,  8.9365e-02,  5.7435e-02,  ...,  4.6573e-02,\n",
            "            3.7369e-02, -1.2676e-01],\n",
            "          [-6.2911e-01, -2.4137e-01, -4.0773e-01,  ..., -6.9293e-01,\n",
            "            3.1935e-02, -4.1883e-01],\n",
            "          [-2.5549e-01,  1.8082e+00, -2.8352e-01,  ..., -4.6622e-01,\n",
            "            1.0279e+00, -9.4012e-01],\n",
            "          ...,\n",
            "          [ 7.4605e-01,  1.0680e+00, -8.8275e-01,  ...,  2.1570e+00,\n",
            "           -1.4945e-01, -1.9842e+00],\n",
            "          [-1.0691e+00,  1.3100e+00,  4.6657e-01,  ...,  1.2517e-01,\n",
            "            4.6400e-01, -1.0356e+00],\n",
            "          [-8.2273e-01,  9.8806e-02, -6.9514e-01,  ..., -2.2223e-01,\n",
            "           -1.0272e-01,  3.9049e-01]],\n",
            "\n",
            "         [[-5.8489e-01, -4.5877e-03,  4.4912e-02,  ..., -2.0796e-02,\n",
            "            6.2989e-03, -6.4938e-03],\n",
            "          [-1.3176e+00, -4.2804e-01, -1.9026e-01,  ...,  5.2456e-01,\n",
            "            8.2973e-01,  1.0469e-01],\n",
            "          [-1.1339e+00,  3.3311e-01, -2.5173e-01,  ...,  6.2253e-01,\n",
            "           -6.0295e-01,  1.3760e-02],\n",
            "          ...,\n",
            "          [-2.3653e+00, -1.5144e-01,  1.3421e-01,  ...,  5.3541e-01,\n",
            "           -2.8095e-01, -1.1765e+00],\n",
            "          [-8.1539e-01, -1.0272e-01,  1.6786e-01,  ..., -9.7565e-01,\n",
            "            4.9931e-01,  3.1859e-01],\n",
            "          [-2.3976e+00, -2.2563e-02,  2.2050e-01,  ..., -4.8616e-01,\n",
            "            4.4922e-01,  6.2526e-01]],\n",
            "\n",
            "         [[ 1.5471e-03,  8.2456e-02, -4.7513e-02,  ...,  5.5853e-02,\n",
            "            3.0368e-02, -4.6994e-02],\n",
            "          [-2.2609e-01,  2.4355e-01, -5.3929e-01,  ..., -2.0829e-01,\n",
            "            1.5472e+00, -3.8645e-01],\n",
            "          [-1.7104e-01,  1.5359e+00,  1.4455e-01,  ...,  1.0122e+00,\n",
            "           -4.8218e-01,  3.8834e-01],\n",
            "          ...,\n",
            "          [-7.4003e-01, -1.4755e+00,  4.0603e-01,  ..., -9.2007e-01,\n",
            "           -2.5029e+00,  8.4800e-01],\n",
            "          [-1.1217e+00, -8.6914e-02, -4.4634e-02,  ...,  1.5705e-01,\n",
            "           -1.4636e+00,  3.7250e-01],\n",
            "          [-6.6446e-01,  2.2474e-01,  2.2329e-01,  ..., -8.1871e-01,\n",
            "            2.0541e-01,  1.4956e+00]]]])), (tensor([[[[-0.0268, -2.3398,  0.1634,  ..., -0.2365, -0.1944,  0.0645],\n",
            "          [-1.1676,  3.9711, -0.1296,  ...,  0.5609, -1.0959,  0.1751],\n",
            "          [-0.8874,  4.6331,  0.5717,  ...,  0.2352, -1.0060,  0.0340],\n",
            "          ...,\n",
            "          [-1.0376,  5.7608,  0.4697,  ...,  0.0796, -0.6596,  0.1551],\n",
            "          [-0.3475,  5.5602, -0.8580,  ..., -0.9931, -1.2877,  0.3541],\n",
            "          [-1.9360,  3.9212, -0.6548,  ..., -1.4439, -0.9667, -0.9640]],\n",
            "\n",
            "         [[-0.8140,  0.2218,  0.4656,  ..., -0.5189,  1.0732,  1.1234],\n",
            "          [ 0.8069,  0.2876,  1.6977,  ...,  0.9986,  1.3092, -0.0675],\n",
            "          [-1.5185,  1.0632,  1.0099,  ..., -0.6639,  0.4247, -0.1393],\n",
            "          ...,\n",
            "          [ 0.1084, -1.9672, -0.0715,  ..., -0.8803, -0.0717, -0.4738],\n",
            "          [-0.0268, -0.8072,  0.4331,  ..., -0.6295,  0.8925,  0.1523],\n",
            "          [-0.6414,  0.1316,  0.9704,  ..., -0.9113,  1.7588,  0.7732]],\n",
            "\n",
            "         [[-0.8504,  0.4700,  0.0232,  ...,  0.4955, -0.2356,  1.1518],\n",
            "          [ 0.3768, -0.9297,  2.0513,  ...,  1.2379,  0.4621,  0.3746],\n",
            "          [ 1.1466, -0.5353,  1.8351,  ..., -0.1052,  0.1681, -1.3665],\n",
            "          ...,\n",
            "          [ 1.7995, -0.0234,  1.2306,  ...,  1.5616,  1.5433,  0.9883],\n",
            "          [ 2.0947, -0.1720,  2.9870,  ...,  1.4164,  0.8424, -1.0065],\n",
            "          [ 1.9132, -0.7083,  2.9818,  ...,  0.7286,  0.9808, -0.4193]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3102, -0.1292,  0.1523,  ...,  0.1793,  1.7438, -2.8696],\n",
            "          [ 0.6903, -0.1718, -0.1144,  ...,  0.3523, -5.0393,  5.2567],\n",
            "          [ 0.6246, -1.3728, -0.2536,  ..., -0.3855, -5.8425,  4.6658],\n",
            "          ...,\n",
            "          [-3.0331, -0.0656,  0.2284,  ...,  0.0554, -4.9116,  6.1333],\n",
            "          [-1.1987, -0.2741,  0.2381,  ..., -0.3221, -4.5426,  5.5112],\n",
            "          [-0.0444, -0.3753,  1.2259,  ...,  0.3065, -5.2526,  4.9173]],\n",
            "\n",
            "         [[ 0.1957,  0.3617,  0.2155,  ..., -0.2170,  0.0182, -0.1540],\n",
            "          [-1.2366, -0.5625, -0.0996,  ...,  0.0593, -0.8357, -0.2929],\n",
            "          [-1.5449,  0.1779, -1.5539,  ...,  0.2225, -0.0291,  0.0088],\n",
            "          ...,\n",
            "          [-0.6597, -0.5007, -0.4138,  ...,  0.6731, -1.2447,  1.2589],\n",
            "          [-0.6272, -0.0816, -0.1229,  ..., -0.1328, -1.0023,  0.3954],\n",
            "          [-0.7232,  0.4547, -1.1136,  ...,  1.2433, -1.5861,  1.1442]],\n",
            "\n",
            "         [[ 0.3722,  0.0987,  0.6134,  ...,  0.5249,  0.5746, -0.3289],\n",
            "          [ 0.1644, -0.8527, -0.5220,  ..., -2.5995, -3.3025,  0.4555],\n",
            "          [-0.5863, -1.3698, -0.4632,  ..., -2.4573, -3.8110,  0.3706],\n",
            "          ...,\n",
            "          [-0.0080,  1.0493, -3.9589,  ..., -0.4468, -5.9489, -0.1719],\n",
            "          [-0.8816,  1.2069, -2.0172,  ..., -0.9922, -5.0986,  0.6780],\n",
            "          [-0.6981,  0.2475, -1.2764,  ..., -0.9308, -3.8143,  0.4571]]]]), tensor([[[[ 5.1168e-02, -7.1119e-03, -1.5924e-02,  ...,  1.3078e-01,\n",
            "           -6.0391e-02, -3.8323e-02],\n",
            "          [-5.8016e-01, -9.2070e-01, -6.2820e-01,  ..., -6.5183e-01,\n",
            "            7.9886e-02,  1.5002e+00],\n",
            "          [-1.0864e+00, -3.2813e-01,  5.1859e-01,  ...,  6.0644e-01,\n",
            "            1.8103e-01, -1.3398e-01],\n",
            "          ...,\n",
            "          [-2.0428e-01,  1.0468e-01,  1.2781e+00,  ..., -2.3276e-02,\n",
            "           -6.1673e-01,  1.1638e+00],\n",
            "          [-2.6795e-01,  7.4859e-01, -2.0992e-01,  ..., -3.5787e-01,\n",
            "           -9.7715e-01,  9.7099e-01],\n",
            "          [ 2.0151e-02,  9.0978e-01, -7.8394e-01,  ..., -1.1107e-01,\n",
            "            6.7354e-01, -7.3452e-01]],\n",
            "\n",
            "         [[ 1.7754e-02,  3.8288e-02,  3.9639e-02,  ...,  6.0098e-03,\n",
            "           -1.8041e-02,  1.0820e-02],\n",
            "          [ 1.0161e+00,  1.2898e+00, -7.7097e-02,  ...,  3.8044e-01,\n",
            "            1.9128e+00,  1.4317e-01],\n",
            "          [-5.9069e-01,  3.1869e-01, -5.3778e-01,  ..., -9.5282e-01,\n",
            "            1.3422e-02,  1.2975e+00],\n",
            "          ...,\n",
            "          [-6.4083e-01,  2.2443e-01, -9.3031e-01,  ...,  1.6250e+00,\n",
            "            8.0855e-02, -3.0090e+00],\n",
            "          [ 1.3036e-01,  1.6986e-01, -1.8161e-01,  ...,  1.1727e-01,\n",
            "            7.4388e-01, -1.2275e+00],\n",
            "          [-1.0648e+00,  7.1219e-01,  6.5640e-01,  ..., -1.7764e+00,\n",
            "           -1.0556e+00, -1.3579e+00]],\n",
            "\n",
            "         [[ 4.9533e-02, -3.8851e-02,  6.1305e-02,  ...,  5.6075e-02,\n",
            "           -7.1068e-02, -6.7331e-02],\n",
            "          [ 4.3573e-01, -9.5483e-02,  5.6943e-01,  ..., -1.0877e+00,\n",
            "            4.6644e-01, -8.5747e-02],\n",
            "          [ 2.6345e-01,  7.6087e-02,  9.7461e-01,  ...,  5.7036e-01,\n",
            "            3.5324e-01,  1.0192e+00],\n",
            "          ...,\n",
            "          [-5.0237e-01,  6.5762e-01, -4.9190e-01,  ..., -6.0205e-01,\n",
            "            1.1641e+00,  5.2953e-01],\n",
            "          [-4.0303e-02, -4.8066e-01,  1.6558e+00,  ..., -1.3963e+00,\n",
            "            7.7573e-01, -9.7269e-02],\n",
            "          [ 5.4854e-02,  1.5950e-01, -2.0095e-01,  ..., -9.6326e-01,\n",
            "            4.9633e-01,  1.5012e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0282e-01, -4.5190e-02,  3.4643e-02,  ..., -8.7064e-02,\n",
            "            4.2705e-02,  9.2013e-03],\n",
            "          [ 8.8288e-01, -7.9516e-01,  2.1677e+00,  ..., -5.5948e-01,\n",
            "           -1.3069e-01,  6.1560e-01],\n",
            "          [ 4.1618e-01, -7.2891e-01, -2.2049e-03,  ..., -7.5425e-01,\n",
            "           -7.3656e-01,  2.4665e+00],\n",
            "          ...,\n",
            "          [-2.4312e+00, -3.7521e-02,  5.4454e-02,  ...,  4.2665e-01,\n",
            "            1.6144e+00,  2.6192e-01],\n",
            "          [-1.4803e+00, -7.9006e-01,  5.8762e-01,  ..., -1.3886e+00,\n",
            "           -1.7840e-01, -1.2854e+00],\n",
            "          [-9.0140e-02, -2.1566e-01,  4.8706e-01,  ..., -8.2001e-01,\n",
            "            3.2120e-01, -3.4294e-01]],\n",
            "\n",
            "         [[ 1.5763e-01, -5.2217e-02,  1.5097e-01,  ...,  7.7618e-02,\n",
            "            3.8919e-02, -1.4855e-01],\n",
            "          [-4.1811e-01,  3.3948e-01,  4.5328e-01,  ...,  1.9658e+00,\n",
            "            1.4565e+00, -5.0197e-01],\n",
            "          [ 3.8000e-01, -1.9466e+00,  4.9931e-01,  ...,  2.1572e+00,\n",
            "            1.6590e+00,  6.1768e-01],\n",
            "          ...,\n",
            "          [ 3.0954e-01,  1.7009e+00,  1.1721e+00,  ...,  2.1619e-01,\n",
            "            6.3193e-01,  1.3235e+00],\n",
            "          [ 7.7348e-01,  2.7802e+00, -6.7288e-01,  ...,  3.1946e-01,\n",
            "            2.6143e-01,  6.7219e-01],\n",
            "          [ 5.0790e-01,  1.1380e+00,  5.4514e-01,  ...,  3.8606e-01,\n",
            "            1.3281e+00, -2.0008e-01]],\n",
            "\n",
            "         [[ 2.0667e-01, -4.3911e-02, -6.8004e-02,  ...,  3.9026e-02,\n",
            "            4.7298e-02,  2.7473e-02],\n",
            "          [-3.0893e-01,  9.7279e-01,  3.9894e-01,  ..., -1.0635e+00,\n",
            "           -1.0877e-01,  1.1288e+00],\n",
            "          [-4.6620e-01,  1.1566e+00,  6.8585e-02,  ...,  7.7100e-01,\n",
            "           -3.2478e-01, -9.4713e-01],\n",
            "          ...,\n",
            "          [ 1.0523e-01,  8.9006e-01,  7.4966e-01,  ..., -1.6435e-01,\n",
            "           -5.6678e-01,  2.5332e+00],\n",
            "          [-7.7902e-01,  1.0588e+00, -7.1927e-01,  ..., -1.0964e+00,\n",
            "            1.8071e-01, -1.1416e+00],\n",
            "          [-1.1954e+00,  4.1489e-01,  3.6759e-01,  ..., -3.8928e-01,\n",
            "           -2.9038e-01,  4.2736e-01]]]])), (tensor([[[[ 0.0436, -0.2509, -0.4550,  ...,  0.3116,  0.3358,  0.3770],\n",
            "          [-0.3936,  0.2447, -0.8455,  ...,  1.2029, -0.7822,  0.7835],\n",
            "          [-0.0892,  0.3507,  1.1133,  ...,  0.7892,  0.6989,  1.1653],\n",
            "          ...,\n",
            "          [ 0.8319, -1.1687, -1.6078,  ...,  1.4572,  0.1158,  0.9720],\n",
            "          [ 1.3988, -0.3903, -1.9179,  ...,  1.8664, -1.1862,  1.1619],\n",
            "          [ 0.5918, -0.6881, -0.9247,  ...,  0.5466, -0.0269,  2.0108]],\n",
            "\n",
            "         [[-0.2801,  0.1559,  0.1167,  ...,  0.0214, -1.1384, -0.1501],\n",
            "          [-1.8979, -0.9232, -1.0917,  ...,  1.1916,  0.9451,  1.2428],\n",
            "          [-0.5571,  0.2608,  0.7689,  ..., -1.5609, -0.3176,  1.2095],\n",
            "          ...,\n",
            "          [-0.4919,  1.9800, -1.7847,  ...,  0.0374,  1.8307, -0.0496],\n",
            "          [-0.6785,  0.7386, -2.1182,  ...,  0.0790,  1.0429,  1.4528],\n",
            "          [-1.0002,  1.1346,  0.4100,  ...,  0.1328,  0.6131,  0.6751]],\n",
            "\n",
            "         [[-1.2411, -0.0878,  0.5490,  ..., -0.6611,  0.4539, -0.2888],\n",
            "          [ 0.5363, -0.2977, -0.8009,  ...,  1.7309, -0.7766, -0.0169],\n",
            "          [ 1.4562,  0.7532, -0.3483,  ...,  1.1714, -0.3751,  1.3159],\n",
            "          ...,\n",
            "          [ 0.8250,  0.3650, -0.4181,  ..., -0.8704, -2.5199,  1.4312],\n",
            "          [ 2.3166,  2.5208,  0.0580,  ..., -0.0476, -0.5278,  0.8616],\n",
            "          [ 1.6525,  2.3032,  0.4888,  ..., -0.0901, -1.3415,  0.6527]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.7973, -0.8987, -0.3939,  ..., -1.0369, -0.4123,  0.4803],\n",
            "          [ 0.2762, -0.5651, -0.4586,  ...,  0.6361, -0.3779, -1.5999],\n",
            "          [ 0.5907,  0.3486, -0.5612,  ...,  0.7038,  0.0770, -0.5581],\n",
            "          ...,\n",
            "          [-0.2512, -0.4268, -1.3554,  ...,  2.7248,  0.4123, -1.3653],\n",
            "          [ 0.7020,  1.0905, -1.5535,  ...,  2.1257,  1.1205, -1.1850],\n",
            "          [ 1.0641,  0.3007, -1.1892,  ...,  1.7041, -0.2648, -1.0517]],\n",
            "\n",
            "         [[-0.9151,  2.5785,  0.3082,  ...,  0.3579,  1.9421, -0.5408],\n",
            "          [ 0.1494, -3.2356, -0.0174,  ..., -0.6429, -5.2464,  1.6909],\n",
            "          [ 0.6226, -3.9038,  1.5556,  ...,  0.4314, -4.0832,  2.0589],\n",
            "          ...,\n",
            "          [ 0.6622, -3.5674,  0.3459,  ...,  0.4120, -4.7875,  0.2499],\n",
            "          [-0.4111, -3.4485,  2.2882,  ...,  0.5834, -5.8643, -1.3149],\n",
            "          [ 0.8257, -2.8683,  0.3954,  ..., -0.7017, -4.8814,  1.0462]],\n",
            "\n",
            "         [[-2.0221, -0.3681, -1.1042,  ..., -0.3983,  0.0527,  0.2442],\n",
            "          [ 1.3658,  0.1714,  1.0706,  ...,  1.0744, -0.6302,  0.3105],\n",
            "          [ 1.9814, -0.5374,  2.1260,  ...,  1.0108, -0.6401,  0.2698],\n",
            "          ...,\n",
            "          [ 4.4413, -0.1954,  0.4186,  ...,  0.0306, -0.7531,  0.6659],\n",
            "          [ 2.8607,  0.4388,  2.4960,  ...,  1.4883,  0.5699, -0.6278],\n",
            "          [ 1.9052,  0.6555,  1.6838,  ...,  0.0059, -0.1376, -0.1016]]]]), tensor([[[[-0.0486, -0.0914,  0.0317,  ...,  0.1226, -0.0363,  0.0125],\n",
            "          [-0.7388,  0.8708, -0.3140,  ...,  0.2039, -0.2249,  0.9142],\n",
            "          [-0.0887, -0.2530, -0.3413,  ...,  1.1572,  0.3358,  0.4971],\n",
            "          ...,\n",
            "          [-0.2872,  1.3841,  0.1368,  ...,  0.4294, -0.1012, -0.9567],\n",
            "          [ 0.8349,  0.5792, -0.1861,  ..., -0.0699,  0.6481, -0.2027],\n",
            "          [ 0.4630, -0.2590, -0.7291,  ...,  1.0840, -0.8006,  0.0685]],\n",
            "\n",
            "         [[ 0.0119,  0.0131, -0.0261,  ...,  0.0464,  0.0287,  0.0569],\n",
            "          [-0.7371,  0.2588, -0.7705,  ...,  1.5141, -1.2460, -0.7485],\n",
            "          [-1.9300, -0.6096, -0.4844,  ...,  0.8999, -0.4722, -0.9141],\n",
            "          ...,\n",
            "          [-0.0505,  1.8448, -0.7843,  ..., -0.7156,  0.9870,  0.7718],\n",
            "          [-0.6063,  0.5351,  0.2557,  ...,  0.6387, -0.0864, -0.3659],\n",
            "          [ 0.2489,  0.4274,  0.3879,  ...,  0.2727, -0.4426,  0.3994]],\n",
            "\n",
            "         [[ 0.0394,  0.0323, -0.0696,  ...,  0.0032,  0.0154,  0.0086],\n",
            "          [ 0.4865, -0.7132,  0.6342,  ...,  0.4271,  0.2193, -0.0260],\n",
            "          [-0.9753, -0.0436, -1.3256,  ...,  1.9029,  0.3162, -0.0475],\n",
            "          ...,\n",
            "          [ 1.9395, -0.0410,  0.0553,  ...,  1.1475,  0.3594,  0.2753],\n",
            "          [ 0.1311,  1.1288, -1.1389,  ...,  0.4666,  1.2058,  1.7724],\n",
            "          [ 0.1394,  1.5343, -0.9379,  ...,  0.1891,  0.9944,  0.5523]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0286,  0.0235, -0.0131,  ..., -0.0338, -0.0418,  0.0161],\n",
            "          [ 0.8847,  0.0316,  1.5987,  ..., -0.7691, -0.1155, -1.6539],\n",
            "          [-0.7558,  0.9497,  1.1171,  ..., -0.0786, -0.3454,  0.0768],\n",
            "          ...,\n",
            "          [-0.4529,  1.5100,  0.4717,  ...,  1.5080, -1.8337, -0.1879],\n",
            "          [ 0.5818,  1.4340,  0.6555,  ...,  0.2547,  0.2101, -1.3094],\n",
            "          [ 0.8302,  0.4506,  0.6030,  ..., -0.4466,  0.5661,  0.0220]],\n",
            "\n",
            "         [[-0.0740, -0.0441,  0.0178,  ...,  0.0031, -0.0459, -0.1092],\n",
            "          [-0.8495, -0.1825, -0.4825,  ...,  1.2022, -0.1713,  0.2325],\n",
            "          [-0.6230,  0.6504, -0.6488,  ...,  1.3487,  0.6046,  0.5663],\n",
            "          ...,\n",
            "          [ 0.8821,  0.0050, -0.4818,  ...,  0.5187,  0.6027, -1.2299],\n",
            "          [-0.3496,  0.0978, -1.4725,  ...,  0.7278,  0.6380,  0.5652],\n",
            "          [-0.6393, -0.3324, -1.1992,  ...,  0.4084, -0.2743,  0.0024]],\n",
            "\n",
            "         [[-0.0078,  0.0402, -0.0565,  ..., -0.0303,  0.0243,  0.0053],\n",
            "          [ 0.0409,  0.2838, -0.5386,  ...,  0.6821, -0.2961, -0.7112],\n",
            "          [-0.7624,  0.3957, -1.2060,  ...,  1.8495,  1.1262, -0.1661],\n",
            "          ...,\n",
            "          [ 0.7426, -0.8367,  1.1867,  ..., -0.2699, -0.7218,  0.4992],\n",
            "          [-0.2764, -0.9626, -0.5587,  ..., -0.1120, -0.5455, -0.2067],\n",
            "          [-1.5894, -0.5886, -0.1812,  ...,  0.0379, -0.5493, -0.0160]]]])), (tensor([[[[-5.2660e-01,  4.8290e-01, -8.5805e-01,  ..., -1.0129e+00,\n",
            "           -1.3275e+00,  2.0395e-01],\n",
            "          [ 7.4353e-01,  1.3545e-01, -3.3650e-01,  ...,  2.3814e+00,\n",
            "            7.8966e-01, -1.3278e+00],\n",
            "          [-5.1632e-01,  1.6959e-01, -2.0632e-01,  ...,  1.6637e+00,\n",
            "           -2.3076e-01, -7.4675e-01],\n",
            "          ...,\n",
            "          [ 2.0140e+00,  7.0385e-02,  1.7288e+00,  ...,  3.8103e+00,\n",
            "            4.6272e-02, -1.4505e+00],\n",
            "          [ 2.6551e-01, -2.8794e-01,  1.2349e+00,  ...,  2.9876e+00,\n",
            "            1.4466e+00,  5.8516e-01],\n",
            "          [ 2.3927e-01,  7.3576e-01,  1.5979e+00,  ...,  3.2609e+00,\n",
            "            2.4128e-03, -2.0494e+00]],\n",
            "\n",
            "         [[ 8.6452e-01, -2.0846e+00,  1.5320e-01,  ...,  2.4595e-01,\n",
            "           -2.4906e+00, -4.5145e-01],\n",
            "          [ 8.0108e-01,  2.3641e+00, -5.8261e-01,  ..., -2.3115e-01,\n",
            "            1.3237e+00, -4.2529e-01],\n",
            "          [ 4.1844e-01,  2.5750e+00, -2.3658e-01,  ...,  1.3680e+00,\n",
            "            7.7556e-01, -1.4195e-01],\n",
            "          ...,\n",
            "          [-9.9340e-01,  3.9391e+00, -9.5642e-01,  ..., -3.8915e-01,\n",
            "            2.8270e+00,  9.9780e-01],\n",
            "          [-4.5046e-01,  3.1355e+00, -1.8579e+00,  ...,  3.6779e-01,\n",
            "            1.4138e+00, -1.9123e-01],\n",
            "          [ 2.5276e-01,  1.4145e+00, -1.5591e+00,  ...,  6.9062e-01,\n",
            "            2.2173e+00, -8.3648e-01]],\n",
            "\n",
            "         [[ 1.0175e+00,  3.8706e-01, -1.7409e-01,  ..., -8.0942e-01,\n",
            "           -1.4149e+00, -3.7303e-01],\n",
            "          [ 3.8518e-02, -3.0625e-01, -6.0075e-01,  ..., -1.7636e-01,\n",
            "            3.8525e-02, -3.2539e-01],\n",
            "          [-1.3575e+00, -3.9286e-01, -2.5127e+00,  ...,  1.4398e+00,\n",
            "           -1.0285e+00,  1.9009e+00],\n",
            "          ...,\n",
            "          [ 6.5391e-01,  1.1018e+00, -1.7289e-01,  ...,  1.3382e+00,\n",
            "           -5.1587e-01,  2.6407e-02],\n",
            "          [ 3.7959e-02,  9.8790e-02, -6.2985e-02,  ...,  1.4794e+00,\n",
            "           -6.4481e-01,  4.4121e-01],\n",
            "          [-2.3561e-01, -4.1938e-01, -3.2314e-01,  ...,  8.7034e-01,\n",
            "           -6.9063e-01, -7.6124e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1372e-01, -5.8138e-01,  4.9170e-01,  ..., -6.7583e-01,\n",
            "            1.0594e+00,  2.8085e-01],\n",
            "          [ 7.3310e-01,  9.5930e-01, -2.1326e+00,  ..., -2.6601e+00,\n",
            "           -1.9221e+00, -2.6271e-01],\n",
            "          [-1.3910e+00,  4.2359e-01, -7.1791e-01,  ..., -2.9821e+00,\n",
            "           -9.2503e-01,  8.9109e-01],\n",
            "          ...,\n",
            "          [-3.8942e+00,  1.2713e+00, -1.4837e+00,  ..., -2.6477e+00,\n",
            "            9.8131e-01,  8.8412e-01],\n",
            "          [-4.8961e+00,  1.0896e+00, -8.4320e-01,  ..., -3.0287e+00,\n",
            "           -5.6148e-01,  1.7627e+00],\n",
            "          [-1.4854e+00, -1.0181e+00, -5.1855e-01,  ..., -3.5943e+00,\n",
            "           -5.1989e-02,  6.9568e-01]],\n",
            "\n",
            "         [[ 2.4313e-01,  5.5281e-01,  5.4387e-01,  ...,  7.4525e-01,\n",
            "            8.5644e-02,  8.4676e-01],\n",
            "          [-3.3567e-01,  1.3385e+00, -5.3103e-01,  ..., -8.1584e-02,\n",
            "           -6.2010e-01,  1.4606e+00],\n",
            "          [ 2.3553e-01,  2.1442e+00, -3.6128e-01,  ...,  8.7807e-01,\n",
            "           -9.2077e-01,  1.1235e+00],\n",
            "          ...,\n",
            "          [-2.0707e-01, -5.0698e-01,  3.0764e-03,  ...,  9.3786e-01,\n",
            "           -1.2753e+00,  5.8196e-02],\n",
            "          [-1.4911e+00,  5.7338e-01, -2.8144e-01,  ...,  7.6260e-01,\n",
            "           -2.9726e-01,  1.0541e+00],\n",
            "          [ 1.1934e+00,  2.3981e+00,  1.6110e+00,  ..., -3.0949e-01,\n",
            "           -5.7745e-01,  2.7979e-01]],\n",
            "\n",
            "         [[-7.0921e-01,  3.1249e-01, -1.6205e+00,  ..., -4.0082e-01,\n",
            "            2.3498e-01, -1.3048e+00],\n",
            "          [ 3.5212e-02, -5.2447e-01, -7.8857e-01,  ...,  1.2526e+00,\n",
            "            2.1236e+00, -7.0521e-01],\n",
            "          [ 5.2272e-02,  1.6463e+00, -3.8712e-01,  ..., -3.3760e-01,\n",
            "            3.2145e-01,  9.0893e-01],\n",
            "          ...,\n",
            "          [-2.1081e-01,  2.4134e+00,  1.0682e-01,  ..., -2.1288e+00,\n",
            "           -2.7463e-01,  3.3941e-01],\n",
            "          [-1.0430e-01,  8.7005e-01, -7.9801e-01,  ..., -1.6095e+00,\n",
            "            2.2769e-01,  2.4146e+00],\n",
            "          [ 8.5430e-02,  1.1163e+00,  9.1480e-01,  ...,  1.2933e+00,\n",
            "            8.8704e-01, -2.7362e-01]]]]), tensor([[[[ 3.4694e-03,  5.2180e-02, -7.1138e-02,  ...,  5.9632e-02,\n",
            "           -5.0955e-02, -7.4279e-02],\n",
            "          [-1.3363e-01,  1.0909e-01,  3.1843e-01,  ..., -6.4185e-01,\n",
            "           -2.3773e-01,  4.9411e-01],\n",
            "          [-3.3390e-01, -7.3781e-01,  7.5075e-01,  ..., -1.6792e-01,\n",
            "           -1.5449e+00,  1.9879e-01],\n",
            "          ...,\n",
            "          [ 5.1200e-01,  3.6081e-01, -6.4722e-02,  ...,  7.3703e-01,\n",
            "           -1.0303e+00, -8.1749e-01],\n",
            "          [ 1.7567e+00, -9.9963e-01, -4.2217e-01,  ...,  6.2596e-01,\n",
            "           -4.6667e-01,  7.1566e-03],\n",
            "          [ 1.6284e+00, -1.0020e+00,  2.4544e-01,  ...,  9.0623e-02,\n",
            "           -1.8005e-01, -1.4814e+00]],\n",
            "\n",
            "         [[ 3.7719e-02,  1.2975e-04,  4.9038e-02,  ..., -3.9138e-02,\n",
            "           -2.6473e-02, -1.4142e-02],\n",
            "          [-5.7026e-01,  4.1352e-02, -8.6540e-02,  ...,  7.2015e-01,\n",
            "            7.5766e-01,  3.1901e-01],\n",
            "          [ 6.5079e-01, -1.3806e-01,  3.3780e-01,  ...,  1.6357e+00,\n",
            "            7.4492e-01,  1.3321e-01],\n",
            "          ...,\n",
            "          [ 5.1398e-01,  9.1810e-01, -3.7549e-01,  ..., -1.2566e+00,\n",
            "           -1.5556e+00, -1.3413e+00],\n",
            "          [-7.9490e-01,  1.7270e+00,  4.7218e-01,  ..., -2.0747e+00,\n",
            "           -4.2329e-01, -9.9206e-02],\n",
            "          [-5.7562e-01,  3.0827e-01, -6.3938e-01,  ...,  8.5150e-01,\n",
            "           -2.0386e-01,  1.5814e+00]],\n",
            "\n",
            "         [[-6.9176e-03,  1.8243e-02, -3.3975e-02,  ...,  8.5669e-03,\n",
            "            2.7227e-02,  5.8461e-02],\n",
            "          [-2.8298e-01,  7.4171e-02,  3.0861e-01,  ...,  6.1790e-01,\n",
            "           -1.2570e+00, -3.9969e-01],\n",
            "          [ 7.0065e-03, -4.8436e-01,  9.5977e-02,  ...,  1.0581e+00,\n",
            "           -1.0377e-01, -1.3291e-01],\n",
            "          ...,\n",
            "          [-8.0943e-01,  2.3036e+00,  1.1561e+00,  ...,  1.0698e+00,\n",
            "           -5.3618e-02,  4.5945e-01],\n",
            "          [-1.2491e+00, -1.4484e+00,  4.0329e-01,  ..., -7.8906e-01,\n",
            "           -6.5381e-01,  1.7849e-01],\n",
            "          [-5.5651e-01,  3.1661e-01,  1.9509e-01,  ...,  3.6510e-02,\n",
            "           -1.5465e+00, -9.3846e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.8410e-02,  2.6667e-02,  1.1429e-02,  ..., -3.5996e-02,\n",
            "           -7.8380e-03,  1.2274e-03],\n",
            "          [-4.9163e-01,  1.2278e+00,  1.6390e+00,  ..., -4.5094e-01,\n",
            "           -4.4382e-01,  1.1440e+00],\n",
            "          [-9.6627e-01, -6.0646e-01,  6.0925e-01,  ...,  1.6018e+00,\n",
            "           -6.6072e-01,  1.9332e+00],\n",
            "          ...,\n",
            "          [ 4.1676e-01, -3.2664e-01,  8.6567e-01,  ...,  2.7050e+00,\n",
            "            2.9744e-01, -3.2473e-01],\n",
            "          [ 5.4044e-02,  1.1234e-01, -3.0830e-01,  ...,  1.2174e+00,\n",
            "           -2.4613e-01,  2.2389e-01],\n",
            "          [ 3.3155e-01,  1.0287e+00,  8.9596e-01,  ...,  8.7831e-01,\n",
            "           -4.6897e-01,  6.9367e-01]],\n",
            "\n",
            "         [[ 7.4373e-02, -1.0839e-03,  4.7472e-02,  ...,  2.5576e-02,\n",
            "            5.5578e-02,  3.0725e-02],\n",
            "          [ 7.7980e-01, -1.3685e+00,  1.7100e+00,  ..., -9.6398e-01,\n",
            "            1.5588e+00,  5.7694e-01],\n",
            "          [ 1.1331e+00,  4.0874e-01, -5.4391e-02,  ..., -7.5779e-01,\n",
            "            1.1875e+00,  1.9258e-01],\n",
            "          ...,\n",
            "          [ 1.1782e+00,  1.3153e-01,  1.8951e+00,  ...,  2.2527e-01,\n",
            "            1.5102e+00, -1.8065e+00],\n",
            "          [ 1.1322e+00, -9.2342e-01, -1.0212e+00,  ...,  1.7933e+00,\n",
            "           -1.9653e-01, -5.1142e-01],\n",
            "          [ 4.3851e-01,  2.3509e+00,  3.6222e+00,  ...,  1.2432e-01,\n",
            "           -4.1750e-01, -2.0495e+00]],\n",
            "\n",
            "         [[-1.1214e-01,  2.7461e-02, -6.8169e-02,  ..., -8.8035e-02,\n",
            "            7.2290e-02, -2.1984e-02],\n",
            "          [-7.8473e-03,  6.2308e-02, -1.4041e+00,  ..., -5.0564e-01,\n",
            "            6.5655e-01,  1.8942e-01],\n",
            "          [ 8.5812e-01,  1.5324e-01,  4.1561e-01,  ..., -4.7017e-01,\n",
            "            4.5722e-01,  1.3280e-01],\n",
            "          ...,\n",
            "          [-2.3590e-01,  7.2213e-02,  1.9552e-01,  ..., -3.4793e-01,\n",
            "           -1.3250e+00, -6.4482e-02],\n",
            "          [-6.4003e-01, -1.5847e-01, -1.0525e+00,  ..., -4.2564e-01,\n",
            "           -1.7431e-01, -4.9548e-01],\n",
            "          [-2.7188e-01,  7.6673e-01, -7.2631e-01,  ..., -1.4011e+00,\n",
            "           -1.5847e+00, -4.5163e-01]]]])), (tensor([[[[-1.7115, -0.3095, -0.3052,  ...,  0.1569,  0.3295, -0.5102],\n",
            "          [ 0.1504,  0.1897, -0.7929,  ...,  0.0186, -1.3572, -0.7899],\n",
            "          [ 0.5056, -0.0861, -0.3157,  ...,  0.2263, -0.5394,  0.0396],\n",
            "          ...,\n",
            "          [ 1.2400,  1.5028, -0.7416,  ...,  1.1763,  0.1236,  1.2157],\n",
            "          [ 1.6400,  0.6640, -0.9355,  ...,  0.0036, -0.3856, -0.4395],\n",
            "          [ 2.2737, -0.2878, -0.4292,  ...,  0.0875, -1.8294, -1.7440]],\n",
            "\n",
            "         [[ 0.1108, -0.0705,  2.3025,  ...,  0.2415,  0.0896, -0.1951],\n",
            "          [ 0.5791, -0.3730, -0.7184,  ..., -0.2213, -0.4097, -0.5254],\n",
            "          [ 0.0877, -0.9508, -0.9043,  ..., -0.5574,  0.3207,  0.1236],\n",
            "          ...,\n",
            "          [ 0.2270,  1.1617, -1.4249,  ..., -0.1707, -0.7564, -0.7772],\n",
            "          [-0.8183,  0.1184, -1.0160,  ...,  0.1335,  0.8097, -1.1240],\n",
            "          [-0.5880, -0.9085, -1.8290,  ...,  0.1303,  0.4730, -0.0373]],\n",
            "\n",
            "         [[-0.2041,  1.0503,  0.4759,  ..., -0.5452,  0.3040, -0.1147],\n",
            "          [-0.9702, -0.0042, -0.3842,  ...,  0.4135,  0.1191, -1.1708],\n",
            "          [-0.8057, -0.5930,  0.3343,  ...,  1.8870,  0.5865, -1.0195],\n",
            "          ...,\n",
            "          [ 0.1232, -1.7790,  0.2788,  ...,  0.8572,  0.7710, -0.9447],\n",
            "          [-0.7366, -1.1497, -0.7430,  ...,  2.0649,  0.8647, -1.3457],\n",
            "          [-0.2500, -0.4411, -0.3708,  ...,  1.5435,  1.3037, -0.9971]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5577,  0.9790, -0.8716,  ..., -0.7184,  0.7245,  0.8611],\n",
            "          [ 0.0526,  0.4052, -0.4604,  ..., -0.6361, -0.4461, -0.9599],\n",
            "          [ 0.8692,  1.5813, -1.4086,  ..., -0.1578, -0.8358, -0.6194],\n",
            "          ...,\n",
            "          [-0.7284,  0.8972, -0.3463,  ..., -0.9050, -0.8512,  1.5413],\n",
            "          [-0.6150,  1.5245,  0.3253,  ...,  0.4300,  0.0546, -0.3834],\n",
            "          [-0.0307,  0.0301,  0.3592,  ..., -0.7351, -1.0606, -0.5544]],\n",
            "\n",
            "         [[-0.4014,  0.3733,  0.3393,  ...,  0.7212,  0.0451, -0.0838],\n",
            "          [-0.8634,  0.7230, -0.7151,  ...,  1.3043, -0.6856, -1.2737],\n",
            "          [-0.2454,  2.4743, -1.1249,  ...,  1.3394, -0.6343, -0.4153],\n",
            "          ...,\n",
            "          [-2.0981,  1.1660, -0.9176,  ...,  1.3319,  0.1888,  0.7234],\n",
            "          [-0.3654,  0.1703, -0.7857,  ...,  2.7200,  0.5881,  1.0805],\n",
            "          [-0.6906,  1.2922, -1.2943,  ...,  0.6019,  0.3719, -0.9117]],\n",
            "\n",
            "         [[-0.7459, -0.0075,  0.4400,  ..., -0.1109,  0.0299, -0.0598],\n",
            "          [-0.5332, -1.1645,  1.6882,  ..., -1.0978, -0.6373,  1.3818],\n",
            "          [ 0.0922, -0.4687,  0.6550,  ...,  0.0129, -0.8378,  0.8066],\n",
            "          ...,\n",
            "          [ 0.1326, -0.9228,  0.4508,  ...,  0.4054, -1.4011,  0.1307],\n",
            "          [ 0.0804, -1.2535,  1.1786,  ...,  0.4145, -0.7242,  0.7941],\n",
            "          [ 0.0464, -0.8028,  2.7552,  ...,  1.6854,  0.9226,  1.0872]]]]), tensor([[[[ 7.7570e-02, -1.1777e-01, -1.6829e-01,  ..., -3.0139e-01,\n",
            "            2.8640e-01, -1.7741e-01],\n",
            "          [-6.9013e-01, -1.0565e-01, -7.6618e-01,  ...,  4.1001e+00,\n",
            "           -3.7273e-01, -6.5496e-02],\n",
            "          [-5.3850e-02,  3.9642e-01,  1.0351e+00,  ...,  1.8154e+00,\n",
            "           -1.5335e+00,  1.3541e+00],\n",
            "          ...,\n",
            "          [ 2.5478e+00,  1.3072e+00, -1.5574e+00,  ...,  1.0114e+00,\n",
            "           -3.2392e+00,  1.5081e+00],\n",
            "          [-8.3411e-01,  7.0592e-02,  1.0381e+00,  ...,  1.6570e+00,\n",
            "            5.4109e-01,  1.5160e+00],\n",
            "          [-1.5656e+00,  2.9976e-01,  2.8113e-01,  ...,  6.2832e-01,\n",
            "           -1.2306e+00,  2.2295e+00]],\n",
            "\n",
            "         [[ 1.0853e-01, -1.0814e-02,  5.5897e-02,  ..., -9.3695e-03,\n",
            "           -8.4395e-02,  1.6578e-01],\n",
            "          [-3.9319e-01,  2.4021e-01,  2.8694e-01,  ..., -1.0962e-01,\n",
            "           -1.6010e+00,  3.5750e-01],\n",
            "          [ 2.9564e-01,  2.0701e-01,  1.1707e+00,  ..., -3.1139e-01,\n",
            "            4.2137e-01, -5.3475e-01],\n",
            "          ...,\n",
            "          [-1.1131e+00,  9.4120e-01,  4.9087e-01,  ..., -1.8270e+00,\n",
            "            1.2121e+00, -1.1872e+00],\n",
            "          [ 1.1732e+00,  3.4765e-01,  7.5869e-01,  ..., -4.8940e-01,\n",
            "           -2.2556e-02,  5.2455e-02],\n",
            "          [ 1.0286e+00,  1.3311e+00,  6.5313e-02,  ..., -4.8073e-02,\n",
            "            5.4289e-01,  8.3458e-01]],\n",
            "\n",
            "         [[-1.3536e-02,  2.5633e-02, -3.8610e-02,  ...,  4.7447e-02,\n",
            "            4.5467e-04,  7.3786e-02],\n",
            "          [ 3.5552e-01, -4.1615e-02,  2.9902e-01,  ..., -6.9425e-01,\n",
            "            1.7264e+00, -3.8617e-01],\n",
            "          [ 1.0678e+00, -2.1771e-01, -3.7911e-01,  ...,  9.0052e-01,\n",
            "           -1.8875e-01,  1.5761e-01],\n",
            "          ...,\n",
            "          [-1.3848e+00,  6.1328e-01,  4.3284e-01,  ...,  5.6377e-01,\n",
            "           -4.1157e-01,  1.6371e+00],\n",
            "          [ 1.7103e-01, -1.9863e-01,  5.8717e-01,  ..., -1.6376e+00,\n",
            "            1.3504e+00, -3.8078e-03],\n",
            "          [ 6.3698e-01, -2.1197e-01, -1.0440e+00,  ..., -5.2583e-01,\n",
            "           -4.9925e-01, -4.8764e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0262e-02, -1.2759e-02,  8.2024e-02,  ...,  4.1477e-02,\n",
            "           -3.4039e-02,  1.6534e-02],\n",
            "          [-6.7002e-01,  1.2635e+00, -9.6898e-02,  ...,  1.1675e+00,\n",
            "           -1.3949e-01,  6.0796e-01],\n",
            "          [ 3.5657e-02,  6.6027e-01,  2.1150e-01,  ..., -1.5006e+00,\n",
            "            5.5440e-01, -1.8333e-02],\n",
            "          ...,\n",
            "          [-2.8941e-01, -1.2628e+00, -2.5532e-01,  ...,  1.3589e+00,\n",
            "            1.3661e-01,  4.3458e-01],\n",
            "          [ 7.9512e-01,  4.2756e-01, -3.1453e-01,  ..., -2.0014e+00,\n",
            "            9.7194e-01,  4.0531e-01],\n",
            "          [-1.1917e-01, -4.9643e-01, -5.2998e-01,  ..., -8.6383e-01,\n",
            "           -8.5475e-01,  3.5878e-01]],\n",
            "\n",
            "         [[-1.8907e-01, -6.5480e-02,  7.6243e-02,  ..., -5.9887e-02,\n",
            "            5.6530e-02, -7.3080e-02],\n",
            "          [-6.2729e-01,  1.5044e+00,  2.4588e-01,  ..., -7.7790e-02,\n",
            "            7.5236e-01, -1.5097e-01],\n",
            "          [-1.1234e+00,  6.7284e-02,  2.5005e-01,  ...,  6.9960e-02,\n",
            "            3.8521e-01,  6.5725e-01],\n",
            "          ...,\n",
            "          [-8.2082e-01, -8.0229e-01,  5.5480e-01,  ..., -2.9698e-01,\n",
            "            7.7984e-02, -1.1747e-01],\n",
            "          [-7.9465e-01, -4.1376e-01, -5.9213e-02,  ...,  6.9611e-01,\n",
            "            8.3951e-01,  1.1962e-01],\n",
            "          [-1.0964e+00, -4.6902e-01,  1.2800e+00,  ..., -5.9766e-01,\n",
            "            4.4902e-01,  1.1794e-01]],\n",
            "\n",
            "         [[ 1.2763e-01, -1.2701e-01,  1.6529e-01,  ..., -1.4527e-01,\n",
            "           -8.5371e-03, -1.7278e-01],\n",
            "          [-1.6845e+00,  3.7512e-01,  1.0838e+00,  ..., -9.8722e-01,\n",
            "           -5.5397e-02, -9.8143e-01],\n",
            "          [-3.7499e-01, -1.1769e+00,  7.6275e-01,  ..., -1.2657e+00,\n",
            "           -1.4848e+00,  3.4202e-01],\n",
            "          ...,\n",
            "          [ 1.0828e+00, -1.7129e-02, -1.8967e+00,  ...,  3.7304e-01,\n",
            "            1.2495e+00,  7.2114e-02],\n",
            "          [-7.4184e-01, -4.4869e-01,  6.5181e-02,  ..., -1.6286e+00,\n",
            "           -4.9993e-01, -1.4785e+00],\n",
            "          [-4.9787e-01,  1.7529e+00, -6.8817e-01,  ...,  8.2369e-01,\n",
            "           -7.7657e-01,  7.0859e-01]]]]))))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# https://huggingface.co/gpt2\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Today I believe we can finally\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# gpt2's vocabulary: https://huggingface.co/gpt2/raw/main/vocab.json\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids, max_length=30,\n",
        "    output_scores=True, return_dict_in_generate=True,\n",
        "    output_attentions=False, do_sample=False\n",
        ")\n",
        "\n",
        "print(\"\\nThe output looks quite messy:\\n\")\n",
        "print(outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIcWIkzx3wmC",
        "outputId": "6f8ddea0-b673-49b6-831a-4f6e570b5781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2's vocabulary is composed of 50257 tokens. Each has a 'word vector' composed of 768 numbers:\n",
            "Embedding(50257, 768)\n",
            "\n",
            "We can look at GPT2's entire vocabulary here: https://huggingface.co/gpt2/raw/main/vocab.json\n",
            "\n",
            "For example, the token 'Love' is at position 18565.\n",
            "\n",
            "We can access it's word vector here (first 100 numbers):\n",
            "\n",
            "tensor([-0.0521,  0.0063,  0.0773,  0.1031, -0.0365, -0.0253, -0.2183,  0.0222,\n",
            "        -0.1285, -0.0917, -0.0771, -0.1728,  0.1625, -0.1056,  0.1838, -0.0049,\n",
            "         0.0246, -0.0203,  0.0717,  0.1154,  0.0384, -0.2783,  0.0206,  0.0678,\n",
            "        -0.1182, -0.0169,  0.0946, -0.1425,  0.1875, -0.0393,  0.1161, -0.4728,\n",
            "         0.1959,  0.0616, -0.1545,  0.0377, -0.3193,  0.1089,  0.0265, -0.0317,\n",
            "         0.1023, -0.0070,  0.0394,  0.0017,  0.1093,  0.1821,  0.1139, -0.0832,\n",
            "         0.0032, -0.0456, -0.0501, -0.0303, -0.0005, -0.2116, -0.0135, -0.2888,\n",
            "        -0.0223,  0.1179,  0.0222,  0.3011,  0.0113,  0.1022, -0.1399, -0.0165,\n",
            "         0.2658,  0.1221, -0.1152, -0.1597,  0.3961,  0.0925,  0.0124,  0.1865,\n",
            "        -0.1736,  0.1215,  0.0576, -0.0720,  0.1281,  0.0823, -0.0360,  0.0325,\n",
            "         0.2140,  0.1219, -0.0035,  0.2351,  0.0536, -0.0379, -0.1372,  0.2510,\n",
            "         0.0493,  0.1837, -0.1628,  0.0623,  0.0266, -0.0706,  0.2387,  0.0577,\n",
            "         0.0005, -0.1481, -0.1461, -0.0766], grad_fn=<SliceBackward0>)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"GPT2's vocabulary is composed of 50257 tokens. Each has a 'word vector' composed of 768 numbers:\")\n",
        "print(model.transformer.wte)\n",
        "\n",
        "print(f\"\"\"\\nWe can look at GPT2's entire vocabulary here: https://huggingface.co/gpt2/raw/main/vocab.json\n",
        "\\nFor example, the token 'Love' is at position 18565.\n",
        "\\nWe can access it's word vector here (first 100 numbers):\\n\n",
        "{model.transformer.wte.weight[18565][:100]}\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dREWnBIZ5q0d",
        "outputId": "b7fa7a81-caca-4b7f-801b-72462f1dcc43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "While the outputs produce by classifiers like BERT are probabilities of classes,\n",
            "the outputs produced by generators like GPT2 are probabilities of tokens.\n",
            "\n",
            "These probabilities of tokens are in the 'outputs' object returned by model.generate()\n",
            "\n",
            "The IDs of the most probably tokens are:\n",
            "tensor([[8888,  314, 1975,  356,  460, 3443,  651,  284,  262,  966,  810,  356,\n",
            "          460,  787,  257, 3580,  287,  262, 3160,  286,  262,  661,  286,  262,\n",
            "         1578, 1829,  286, 2253,   13,  198]])\n",
            "\n",
            "These token IDs can be mapped to actuall words/tokens in the vocabulary:\n",
            "['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']\n",
            "\n",
            "\n",
            "\n",
            "Our original prompt was:\n",
            "'Today I believe we can finally'\n",
            "GPT2 then tries to predict the most probable next token. One token after the other.\n",
            "\n",
            "To calculate the first token, it makes a prediction over ALL of the 50257 tokens it knows.\n",
            "Each of the 50257 tokens receives a probability.\n",
            "First the first token, the probability distribution over its ENTIRE vocabulary looks like this:\n",
            "tensor([-148.6821, -149.2908, -156.0585,  ..., -162.4585, -158.8699,\n",
            "        -150.9391])\n",
            "\n",
            "The ID of the most probable *first* token is 651\n",
            "The corresponding token is:  get\n",
            "\n",
            "The ID of the most probable *second* token is 284\n",
            "The corresponding token is:  to\n",
            "\n",
            "The ID of the most probable *third* token is 262\n",
            "The corresponding token is:  the\n",
            "\n",
            "This is how GPT2 gradually generated the text:\n",
            "['Today I believe we can finally get to the point where we can make a difference in the lives of the people of the United States of America.\\n']\n",
            "\n",
            "The same principles apply to all generative LLMs like GPT4, Llama-2 etc.\n",
            "Only that they are bigger, with a better architecture and better fine-tuning.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"\"\"\n",
        "While the outputs produce by classifiers like BERT are probabilities of classes,\n",
        "the outputs produced by generators like GPT2 are probabilities of tokens.\n",
        "\\nThese probabilities of tokens are in the 'outputs' object returned by model.generate()\n",
        "\\nThe IDs of the most probably tokens are:\n",
        "{outputs.sequences}\n",
        "\\nThese token IDs can be mapped to actuall words/tokens in the vocabulary:\n",
        "{tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)}\\n\\n\n",
        "\n",
        "Our original prompt was:\\n'{prompt}'\n",
        "GPT2 then tries to predict the most probable next token. One token after the other.\n",
        "\n",
        "To calculate the first token, it makes a prediction over ALL of the 50257 tokens it knows.\n",
        "Each of the 50257 tokens receives a probability.\n",
        "First the first token, the probability distribution over its ENTIRE vocabulary looks like this:\n",
        "{outputs.scores[0][0]}\n",
        "\n",
        "The ID of the most probable *first* token is {torch.argmax(outputs.scores[0][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[0][0], dim=0))}\n",
        "\n",
        "The ID of the most probable *second* token is {torch.argmax(outputs.scores[1][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[1][0], dim=0))}\n",
        "\n",
        "The ID of the most probable *third* token is {torch.argmax(outputs.scores[2][0], dim=0)}\n",
        "The corresponding token is: {tokenizer.decode(torch.argmax(outputs.scores[2][0], dim=0))}\n",
        "\n",
        "This is how GPT2 gradually generated the text:\n",
        "{tokenizer.batch_decode(outputs.sequences, skip_special_tokens=True)}\n",
        "\n",
        "The same principles apply to all generative LLMs like GPT4, Llama-2 etc.\n",
        "Only that they are bigger, with a better architecture and better fine-tuning.\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjTJh6DaMsSc"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLBWZ7tJ6K7b"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja80SRkiLP50"
      },
      "source": [
        "## Reflection  +  Q&A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8uhW4V_AU-m"
      },
      "source": [
        "\n",
        "**Reading, thinking & asking:** (5 min)\n",
        "* Write your answers to the following questions on a piece of paper / digital notebook. While thinking about these questions, also don't hesitate to ask any questions that come up in the chat/Slack.\n",
        "    * In your own words, write down the main differences between models like BERT and models like GPT with regard to their outputs.\n",
        "    * What could be disadvantages and advantages of these two different approaches (encoders vs. decoders)?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In your own words, write down the main differences between models like BERT and models like GPT with regard to their outputs.\n",
        "\n",
        "The main difference between BERT and GPT models lies in their use cases and the nature of their outputs.\n",
        "\n",
        "Models like BERT are designed to understand and interpret input text, so they're the best approach for tasks like sentence classification, named entity recognition, and question answering. The outputs generated by these models are contextualized embeddings where the representation of each word or token takes into account the entire sequence of words. The models capture the meaning of each token within the context of the entire input sequence, and have a deeper understanding.\n",
        "\n",
        "GPT and similar models are designed for text generation tasks because they generate coherent and contextually relevant text. Their outputs are sequences of text resulting from predictions of the next token based on the preceding tokens.\n",
        "\n",
        "* What could be disadvantages and advantages of these two different approaches (encoders vs. decoders)?\n",
        "\n",
        "**Encoders**\n",
        "Encoders benefit from being bidirectional which allows them to understand context deeply, very beneficial for tasks that require a nuanced understanding of language. Encoders can be fine-tuned for a broader set of tasks that requires analysing the input given, such as sentence classification, named entity recognition, and question answering.\n",
        "\n",
        "However, encoders bidirectional nature requires processing the information in both directions, making them more computationally expensive.\n",
        "\n",
        "\n",
        "**Decoders**\n",
        "\n",
        "Decoders, like GPT, are designed for text generation, as they're able to generate natural text that is contextually relevant, just by predicting what comes next in a sentence.\n",
        "Compared to encoders, decoders are less computationally expensive and easier to train, as they operate in a unidirectional manner.\n",
        "However, because they focus more on the flow of text, they might miss some of the deeper meanings in longer passages and provide innacurate outputs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8MsgI7jlAAaw"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}